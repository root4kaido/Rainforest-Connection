{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch==1.6.0 in /home/user/.local/lib/python3.6/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy in /home/user/.local/lib/python3.6/site-packages (from torch==1.6.0) (1.19.4)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0) (0.18.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/user/.local/lib/python3.6/site-packages (4.4.0.46)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/user/.local/lib/python3.6/site-packages (from opencv-python) (1.19.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchvision==0.7.0\n",
      "  Downloading torchvision-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 10.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/user/.local/lib/python3.6/site-packages (from torchvision==0.7.0) (1.19.4)\n",
      "Requirement already satisfied: torch==1.6.0 in /home/user/.local/lib/python3.6/site-packages (from torchvision==0.7.0) (1.6.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0) (7.2.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchvision==0.7.0) (0.18.2)\n",
      "Installing collected packages: torchvision\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.2.2\n",
      "    Uninstalling torchvision-0.2.2:\n",
      "      Successfully uninstalled torchvision-0.2.2\n",
      "Successfully installed torchvision-0.7.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: albumentations in /home/user/.local/lib/python3.6/site-packages (0.5.2)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /home/user/.local/lib/python3.6/site-packages (from albumentations) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations) (5.3.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.1.0)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /home/user/.local/lib/python3.6/site-packages (from albumentations) (0.17.2)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /home/user/.local/lib/python3.6/site-packages (from albumentations) (4.4.0.46)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/user/.local/lib/python3.6/site-packages (from albumentations) (1.19.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (3.0.0)\n",
      "Requirement already satisfied: opencv-python in /home/user/.local/lib/python3.6/site-packages (from imgaug>=0.4.0->albumentations) (4.4.0.46)\n",
      "Requirement already satisfied: Shapely in /home/user/.local/lib/python3.6/site-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n",
      "Requirement already satisfied: imageio in /home/user/.local/lib/python3.6/site-packages (from imgaug>=0.4.0->albumentations) (2.9.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (7.2.0)\n",
      "Requirement already satisfied: six in /home/user/.local/lib/python3.6/site-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/user/.local/lib/python3.6/site-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/user/.local/lib/python3.6/site-packages (from scikit-image>=0.16.1->albumentations) (2020.9.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.7.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.2.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug>=0.4.0->albumentations) (49.6.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/user/.local/lib/python3.6/site-packages (2.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/user/.local/lib/python3.6/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/user/.local/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/user/.local/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/user/.local/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/user/.local/lib/python3.6/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /home/user/.local/lib/python3.6/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/user/.local/lib/python3.6/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/user/.local/lib/python3.6/site-packages (from tensorflow) (1.19.4)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/user/.local/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /home/user/.local/lib/python3.6/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /home/user/.local/lib/python3.6/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/user/.local/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/user/.local/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/user/.local/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/user/.local/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (1.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (49.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/user/.local/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/user/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/user/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/user/.local/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/user/.local/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytorch-lightning in /home/user/.local/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied: fsspec>=0.8.0 in /home/user/.local/lib/python3.6/site-packages (from pytorch-lightning) (0.8.5)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/user/.local/lib/python3.6/site-packages (from pytorch-lightning) (2.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (5.3.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/user/.local/lib/python3.6/site-packages (from pytorch-lightning) (4.54.1)\n",
      "Requirement already satisfied: torch>=1.3 in /home/user/.local/lib/python3.6/site-packages (from pytorch-lightning) (1.6.0)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (0.18.2)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/user/.local/lib/python3.6/site-packages (from pytorch-lightning) (1.19.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.24.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.32.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.14.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.10.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (49.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/user/.local/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (1.7.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/user/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/user/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/user/.local/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/user/.local/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.6.0\n",
    "!pip install opencv-python\n",
    "!pip install torchvision==0.7.0\n",
    "!pip install albumentations\n",
    "!pip install tensorflow\n",
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.1.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 1.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/user/.local/lib/python3.6/site-packages (from transformers) (1.19.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/user/.local/lib/python3.6/site-packages (from transformers) (4.55.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Collecting tokenizers==0.9.4\n",
      "  Downloading tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 2.1 MB/s \n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2020.11.13-cp36-cp36m-manylinux2014_x86_64.whl (723 kB)\n",
      "\u001b[K     |████████████████████████████████| 723 kB 4.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.2.2)\n",
      "Requirement already satisfied: six in /home/user/.local/lib/python3.6/site-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.25.10)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 4.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Collecting click\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 1.9 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893258 sha256=012e87548fcdc737b5caae9fd67fb1363301bb419418474a742bf1e0c605ef0f\n",
      "  Stored in directory: /home/user/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: regex, click, tokenizers, sacremoses, transformers\n",
      "\u001b[33m  WARNING: The script sacremoses is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed click-7.1.2 regex-2020.11.13 sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchlibrosa\n",
      "  Downloading torchlibrosa-0.0.5-py3-none-any.whl (8.9 kB)\n",
      "Installing collected packages: torchlibrosa\n",
      "Successfully installed torchlibrosa-0.0.5\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchlibrosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import typing as tp\n",
    "import yaml\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "# import resnest.torch as resnest_torch\n",
    "\n",
    "from torchvision import models\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "# from mixup import do_mixup\n",
    "import random\n",
    "from timm.models.efficientnet import tf_efficientnet_b0_ns\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "# from resnet import ResNet, Bottleneck\n",
    "\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "import albumentations as A\n",
    "from audiomentations import Compose, AddGaussianSNR, AddGaussianNoise, PitchShift, AddBackgroundNoise, AddShortNoises, Gain, PitchShift\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1213\n",
    "PERIOD = 10\n",
    "OK_RANGE = 100\n",
    "SPECIES_NUM = 24\n",
    "EPOCH = 25\n",
    "OUTPUT_DIR = './output/'\n",
    "HOP_LEN = 512\n",
    "SR = 48000\n",
    "EPSILON_FP16 = 1e-5\n",
    "MEL_BIN = 384\n",
    "ASOBI = 0\n",
    "NO_LABEL = -1\n",
    "\n",
    "config_set = {\n",
    "    'dataset': {\n",
    "          'name': 'SpectrogramDataset',\n",
    "          'params': {\n",
    "            'img_size': 224, \n",
    "            'melspectrogram_parameters': {\n",
    "                'n_fft': 2048,\n",
    "                'hop_length': 512,\n",
    "                'win_length': 2048,\n",
    "                'n_mels': MEL_BIN, \n",
    "                'fmin': 50, \n",
    "                'fmax': 24000, \n",
    "            }\n",
    "      }\n",
    "    },\n",
    "    'loader': {\n",
    "      'train': {\n",
    "        'batch_size': 6,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 2,\n",
    "        'pin_memory': True,\n",
    "        'drop_last': True,\n",
    "      },\n",
    "      'valid': {\n",
    "        'batch_size': 2,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 2,\n",
    "        'pin_memory': True,\n",
    "        'drop_last': True,\n",
    "      }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_ROOT = Path(\"/home/knikaido/work/Rainforest-Connection/data\")\n",
    "RAW_DATA = INPUT_ROOT / \"rfcx-species-audio-detection\"\n",
    "TRAIN_AUDIO_DIR = RAW_DATA / \"train\"\n",
    "# TRAIN_RESAMPLED_AUDIO_DIRS = [\n",
    "#   INPUT_ROOT / \"birdsong-resampled-train-audio-{:0>2}\".format(i)  for i in range(5)\n",
    "# ]\n",
    "TEST_AUDIO_DIR = RAW_DATA / \"test\"\n",
    "pinknoise_dir = INPUT_ROOT / 'pinknoise_resample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation():\n",
    "    list_of_aug = [\n",
    "    #         AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.3),\n",
    "        AddGaussianNoise(p=0.2),\n",
    "        AddGaussianSNR(p=0.2),\n",
    "        Gain(min_gain_in_db=-15,max_gain_in_db=15,p=0.3),\n",
    "        PitchShift(min_semitones=-1, max_semitones=1, p=0.2)\n",
    "#         AddBackgroundNoise(str(pinknoise_dir),p=0.2),\n",
    "#         AddShortNoises(str(pinknoise_dir),min_time_between_sounds=0.0, max_time_between_sounds=15.0, burst_probability=0.5, p=0.6)\n",
    "    ]\n",
    "    return Compose(list_of_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>songtype_id</th>\n",
       "      <th>t_min</th>\n",
       "      <th>f_min</th>\n",
       "      <th>t_max</th>\n",
       "      <th>f_max</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003bec244</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>44.5440</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.1307</td>\n",
       "      <td>5531.25</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006ab765f</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39.9615</td>\n",
       "      <td>7235.160</td>\n",
       "      <td>46.0452</td>\n",
       "      <td>11283.40</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007f87ba2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>39.1360</td>\n",
       "      <td>562.500</td>\n",
       "      <td>42.2720</td>\n",
       "      <td>3281.25</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0099c367b</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>51.4206</td>\n",
       "      <td>1464.260</td>\n",
       "      <td>55.1996</td>\n",
       "      <td>4565.04</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009b760e6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0854</td>\n",
       "      <td>947.461</td>\n",
       "      <td>52.5293</td>\n",
       "      <td>10852.70</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>fe8d9ac40</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>53.4720</td>\n",
       "      <td>93.750</td>\n",
       "      <td>54.0960</td>\n",
       "      <td>843.75</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>fea6b438a</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>43.5787</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.7653</td>\n",
       "      <td>4031.25</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>ff2eb9ce5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2267</td>\n",
       "      <td>5906.250</td>\n",
       "      <td>16.0213</td>\n",
       "      <td>8250.00</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>ffb8d8391</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14.3467</td>\n",
       "      <td>4781.250</td>\n",
       "      <td>16.6987</td>\n",
       "      <td>10406.20</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>ffb9a7b9a</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>40.3200</td>\n",
       "      <td>3187.500</td>\n",
       "      <td>41.0133</td>\n",
       "      <td>5062.50</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1216 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     recording_id  species_id  songtype_id    t_min     f_min    t_max  \\\n",
       "0       003bec244          14            1  44.5440  2531.250  45.1307   \n",
       "1       006ab765f          23            1  39.9615  7235.160  46.0452   \n",
       "2       007f87ba2          12            1  39.1360   562.500  42.2720   \n",
       "3       0099c367b          17            4  51.4206  1464.260  55.1996   \n",
       "4       009b760e6          10            1  50.0854   947.461  52.5293   \n",
       "...           ...         ...          ...      ...       ...      ...   \n",
       "1211    fe8d9ac40          13            1  53.4720    93.750  54.0960   \n",
       "1212    fea6b438a           4            1  43.5787  2531.250  45.7653   \n",
       "1213    ff2eb9ce5           0            1  15.2267  5906.250  16.0213   \n",
       "1214    ffb8d8391           5            1  14.3467  4781.250  16.6987   \n",
       "1215    ffb9a7b9a          18            1  40.3200  3187.500  41.0133   \n",
       "\n",
       "         f_max                                               name  \n",
       "0      5531.25  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1     11283.40  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "2      3281.25  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "3      4565.04  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "4     10852.70  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "...        ...                                                ...  \n",
       "1211    843.75  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1212   4031.25  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1213   8250.00  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1214  10406.20  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1215   5062.50  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "\n",
       "[1216 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_pickle(RAW_DATA / \"train_gby_wav_raw_denoise.pkl\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>songtype_id</th>\n",
       "      <th>t_min</th>\n",
       "      <th>f_min</th>\n",
       "      <th>t_max</th>\n",
       "      <th>f_max</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003bec244</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[44.544]</td>\n",
       "      <td>[2531.25]</td>\n",
       "      <td>[45.1307]</td>\n",
       "      <td>[5531.25]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006ab765f</td>\n",
       "      <td>[23]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[39.9615]</td>\n",
       "      <td>[7235.16]</td>\n",
       "      <td>[46.0452]</td>\n",
       "      <td>[11283.4]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007f87ba2</td>\n",
       "      <td>[12]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[39.135999999999996]</td>\n",
       "      <td>[562.5]</td>\n",
       "      <td>[42.272]</td>\n",
       "      <td>[3281.25]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0099c367b</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[51.4206]</td>\n",
       "      <td>[1464.26]</td>\n",
       "      <td>[55.1996]</td>\n",
       "      <td>[4565.04]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009b760e6</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[50.0854]</td>\n",
       "      <td>[947.461]</td>\n",
       "      <td>[52.5293]</td>\n",
       "      <td>[10852.7]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>fe8d9ac40</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[53.472]</td>\n",
       "      <td>[93.75]</td>\n",
       "      <td>[54.096000000000004]</td>\n",
       "      <td>[843.75]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>fea6b438a</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[43.5787]</td>\n",
       "      <td>[2531.25]</td>\n",
       "      <td>[45.7653]</td>\n",
       "      <td>[4031.25]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>ff2eb9ce5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[15.2267]</td>\n",
       "      <td>[5906.25]</td>\n",
       "      <td>[16.0213]</td>\n",
       "      <td>[8250.0]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>ffb8d8391</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[14.3467]</td>\n",
       "      <td>[4781.25]</td>\n",
       "      <td>[16.6987]</td>\n",
       "      <td>[10406.2]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>ffb9a7b9a</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[40.32]</td>\n",
       "      <td>[3187.5]</td>\n",
       "      <td>[41.0133]</td>\n",
       "      <td>[5062.5]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1132 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     recording_id species_id songtype_id                 t_min      f_min  \\\n",
       "0       003bec244       [14]         [1]              [44.544]  [2531.25]   \n",
       "1       006ab765f       [23]         [1]             [39.9615]  [7235.16]   \n",
       "2       007f87ba2       [12]         [1]  [39.135999999999996]    [562.5]   \n",
       "3       0099c367b       [17]         [4]             [51.4206]  [1464.26]   \n",
       "4       009b760e6       [10]         [1]             [50.0854]  [947.461]   \n",
       "...           ...        ...         ...                   ...        ...   \n",
       "1127    fe8d9ac40       [13]         [1]              [53.472]    [93.75]   \n",
       "1128    fea6b438a        [4]         [1]             [43.5787]  [2531.25]   \n",
       "1129    ff2eb9ce5        [0]         [1]             [15.2267]  [5906.25]   \n",
       "1130    ffb8d8391        [5]         [1]             [14.3467]  [4781.25]   \n",
       "1131    ffb9a7b9a       [18]         [1]               [40.32]   [3187.5]   \n",
       "\n",
       "                     t_max      f_max  \\\n",
       "0                [45.1307]  [5531.25]   \n",
       "1                [46.0452]  [11283.4]   \n",
       "2                 [42.272]  [3281.25]   \n",
       "3                [55.1996]  [4565.04]   \n",
       "4                [52.5293]  [10852.7]   \n",
       "...                    ...        ...   \n",
       "1127  [54.096000000000004]   [843.75]   \n",
       "1128             [45.7653]  [4031.25]   \n",
       "1129             [16.0213]   [8250.0]   \n",
       "1130             [16.6987]  [10406.2]   \n",
       "1131             [41.0133]   [5062.5]   \n",
       "\n",
       "                                                   name  \n",
       "0     /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1     /home/knikaido/work/Rainforest-Connection/data...  \n",
       "2     /home/knikaido/work/Rainforest-Connection/data...  \n",
       "3     /home/knikaido/work/Rainforest-Connection/data...  \n",
       "4     /home/knikaido/work/Rainforest-Connection/data...  \n",
       "...                                                 ...  \n",
       "1127  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1128  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1129  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1130  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1131  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "\n",
       "[1132 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gby = pd.read_pickle(RAW_DATA / \"train_gby_denoise.pkl\")\n",
    "train_gby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2880000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, sr = sf.read(train_df['name'][0])\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/knikaido/work/Rainforest-Connection/data/rfcx-species-audio-detection/train_denoise/dabd22b08_denoise.flac'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(train_df['name']), 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramTrainDataset(data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gby_df: pd.DataFrame,\n",
    "        setting: tp.Dict\n",
    "    ):\n",
    "        self.img_size = setting['img_size']\n",
    "        self.melspectrogram_parameters = setting['melspectrogram_parameters']\n",
    "        self.transform = get_augmentation()\n",
    "        \n",
    "        self.gby_df = gby_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gby_df) * 2\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \n",
    "        if idx >= len(self.gby_df['name']):\n",
    "            audio, label = self.get_unlabeled_item(idx)\n",
    "            # For unlabeled samples, we zero out the classification loss.\n",
    "            classif_weights = np.zeros(SPECIES_NUM, dtype='f')\n",
    "        else:\n",
    "            audio, label= self.get_labeled_item(idx)\n",
    "            classif_weights = np.ones(SPECIES_NUM, dtype='f')\n",
    "            \n",
    "        audio_teacher = np.copy(audio)\n",
    "\n",
    "        # The 2 samples fed to the 2 models have should have different augmentations.\n",
    "        audio = self.transform(samples=audio, sample_rate=sr)\n",
    "        audio_teacher = self.transform(samples=audio_teacher, sample_rate=sr)\n",
    "        # assert (audio != audio_teacher).any()\n",
    "        \n",
    "        return {\n",
    "            \"waveform\": audio,\n",
    "            \"teacher_waveform\": audio_teacher,\n",
    "            \"target\": label,\n",
    "            \"classification_weights\": classif_weights\n",
    "        }\n",
    "            \n",
    "    def get_labeled_item(self, idx):\n",
    "\n",
    "        wav_path = self.gby_df['name'][idx]\n",
    "        train_element = self.gby_df.iloc[idx]\n",
    "\n",
    "        y, sr = sf.read(wav_path)\n",
    "\n",
    "        len_y = len(y)\n",
    "        effective_length = int(sr * PERIOD)\n",
    "\n",
    "        tmin = max(SR * (train_element['t_min'] - ASOBI), SR * 0.001)\n",
    "        tmax = min(SR * (train_element['t_max'] + ASOBI), len_y - ( SR * 0.001 ))      \n",
    "\n",
    "        start_min = max(0, tmax-effective_length)\n",
    "        start_max = min(tmin, len_y - effective_length)\n",
    "        start = np.random.randint(start_min, start_max)\n",
    "        end = start + effective_length\n",
    "\n",
    "        y = y[start:end].astype(np.float32)\n",
    "        y = self.transform(samples=y, sample_rate=sr)\n",
    "\n",
    "        label = np.zeros(SPECIES_NUM, dtype=\"f\")\n",
    "        label[train_element['species_id']] = 1\n",
    "\n",
    "        return y, label\n",
    "\n",
    "    def get_unlabeled_item(self, idx, random_sample=False):\n",
    "        real_idx = idx - len(self.gby_df['name'])\n",
    "        # We want our validation set to be fixed.\n",
    "#             if self.val:\n",
    "#                 rec_id = self.recording_ids[real_idx]\n",
    "#             else:\n",
    "        wav_path = random.sample(list(self.gby_df['name']), 1)[0]\n",
    "        y, sr = sf.read(wav_path)\n",
    "\n",
    "        len_y = len(y)\n",
    "        effective_length = int(sr * PERIOD)\n",
    "        max_end = len_y - effective_length\n",
    "#             if self.val:\n",
    "#                 # Fixed start for validation. Probaably a better way to do this.\n",
    "#                 start = int(idx * 16963 % max_end)\n",
    "#             else:\n",
    "        start = np.random.randint(0, max_end)\n",
    "        y = y[start:(start+effective_length)]\n",
    "        y = y.astype(np.float32)\n",
    "\n",
    "        label = np.ones(SPECIES_NUM, dtype='f') * NO_LABEL\n",
    "\n",
    "        return y, label\n",
    "    \n",
    "class SpectrogramValidDataset(data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gby_df: pd.DataFrame,\n",
    "        setting: tp.Dict\n",
    "    ):\n",
    "        self.img_size = setting['img_size']\n",
    "        self.melspectrogram_parameters = setting['melspectrogram_parameters']\n",
    "        \n",
    "        self.gby_df = gby_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gby_df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \n",
    "        wav_path = self.gby_df['name'][idx]\n",
    "        train_element = self.gby_df.iloc[idx]\n",
    "        \n",
    "        y, sr = sf.read(wav_path)\n",
    "        \n",
    "        len_y = len(y)\n",
    "        effective_length = int(sr * PERIOD)\n",
    "\n",
    "        tmin = int(SR * train_element['t_min'])\n",
    "        tmax = int(SR * train_element['t_max'])\n",
    "        \n",
    "        #時間かかる\n",
    "        while(1):\n",
    "            start = np.random.randint(len_y - effective_length)\n",
    "            end = start + effective_length\n",
    "            tgt_len = int((tmax - tmin) * 100 / 100)\n",
    "            if( (start < tmin and tmin + tgt_len < end) or (start < tmax - tgt_len and tmax < end) ):\n",
    "                break\n",
    "        \n",
    "        y = y[start:end].astype(np.float32)\n",
    "        \n",
    "        label = np.zeros(SPECIES_NUM, dtype=\"f\")\n",
    "        label[train_element['species_id']] = 1\n",
    "\n",
    "        return y, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_criterion(y_pred, y_true, isTrain=True):\n",
    "    y_pred = torch.clamp(y_pred, min=EPSILON_FP16, max=1.0-EPSILON_FP16)\n",
    "#     loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "    bce_loss = nn.BCELoss()(y_pred, y_true)\n",
    "    \n",
    "    if isTrain == True:\n",
    "        gamma = 2\n",
    "        alpha = 0.5\n",
    "        bce_loss = y_true * alpha * (1. - y_pred)**gamma * bce_loss + (1. -  y_true) *  y_pred**gamma * bce_loss\n",
    "        bce_loss = bce_loss.mean()\n",
    "    \n",
    "    return bce_loss\n",
    "\n",
    "def sigmoid_rampup(current, rampup_length):\n",
    "    \"\"\"Exponential rampup from https://arxiv.org/abs/1610.02242\"\"\"\n",
    "    if rampup_length == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        current = np.clip(current, 0.0, rampup_length)\n",
    "        phase = 1.0 - current / rampup_length\n",
    "        return float(np.exp(-5.0 * phase * phase))\n",
    "\n",
    "def sigmoid_mse_loss(input_logits, target_logits):\n",
    "    assert input_logits.size() == target_logits.size()\n",
    "    input_softmax = torch.sigmoid(input_logits)\n",
    "#     input_softmax = input_logits\n",
    "    target_softmax = torch.sigmoid(target_logits)\n",
    "    num_classes = input_logits.size()[1]\n",
    "    return F.mse_loss(input_softmax, target_softmax, size_average=False\n",
    "                     ) / num_classes\n",
    "\n",
    "class MeanTeacherLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.positive_weight = torch.ones(\n",
    "            SPECIES_NUM).to('cuda') * 2.0\n",
    "        self.class_criterion = nn.BCEWithLogitsLoss(\n",
    "            reduction='none', pos_weight=self.positive_weight)\n",
    "#         self.class_criterion = bce_criterion\n",
    "        self.consistency_criterion = sigmoid_mse_loss\n",
    "        self.consistency_weight = 100\n",
    "        self.consistency_rampup = 1000\n",
    "\n",
    "    def make_safe(self, pred):\n",
    "        pred = torch.where(torch.isnan(pred), torch.zeros_like(pred), pred)\n",
    "        return torch.where(torch.isinf(pred), torch.zeros_like(pred), pred)\n",
    "        \n",
    "    def get_consistency_weight(self, epoch):\n",
    "        # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
    "        return self.consistency_weight * sigmoid_rampup(\n",
    "            epoch, self.consistency_rampup)\n",
    "    \n",
    "    def forward(self, student_pred, teacher_pred, target, classif_weights, epoch):\n",
    "        student_pred = self.make_safe(student_pred)\n",
    "        teacher_pred = self.make_safe(teacher_pred).detach().data\n",
    "\n",
    "        batch_size = len(target)\n",
    "        labeled_batch_size = target.ne(NO_LABEL).all(axis=1).sum().item() + 1e-3\n",
    "\n",
    "        student_classif, student_consistency = student_pred, student_pred\n",
    "        student_class_loss = (self.class_criterion(\n",
    "            student_classif, target) * classif_weights / labeled_batch_size).sum()\n",
    "\n",
    "        consistency_weights = self.get_consistency_weight(epoch)\n",
    "        consistency_loss = consistency_weights * self.consistency_criterion(\n",
    "            student_consistency, teacher_pred) / batch_size\n",
    "        loss = student_class_loss + consistency_loss\n",
    "        return loss, student_class_loss, consistency_loss, consistency_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='valid_epoch_lwlap',\n",
    "   min_delta=0.00,\n",
    "   patience=5,\n",
    "   verbose=True,\n",
    "   mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4167)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "def lwlrap(truth, scores):\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = _one_sample_positive_class_precisions(scores[sample_num, :], truth[sample_num, :])\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = precision_at_hits\n",
    "\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    return per_class_lwlrap, weight_per_class\n",
    "\n",
    "def lwlap_wrapper(y_true, y_score):\n",
    "    y_true = y_true.cpu()\n",
    "    y_score = y_score.cpu()\n",
    "    y_true = y_true.to('cpu').detach().numpy().copy()\n",
    "    y_score = y_score.to('cpu').detach().numpy().copy()\n",
    "    score_class, weight = lwlrap(y_true, y_score)\n",
    "    score_class = torch.from_numpy(score_class.astype(np.float32)).clone()\n",
    "    weight = torch.from_numpy(weight.astype(np.float32)).clone()\n",
    "    return score_class, weight\n",
    "\n",
    "y_true = np.array([[1, 0, 0], [0, 0, 1]])\n",
    "y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])\n",
    "y_true = torch.from_numpy(y_true.astype(np.float32)).clone()\n",
    "y_score = torch.from_numpy(y_score.astype(np.float32)).clone()\n",
    "\n",
    "score_class, weight = lwlap_wrapper(y_true, y_score)\n",
    "score = (score_class * weight).sum()\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    pad = framewise_output[:, -1:, :].repeat(\n",
    "        1, frames_num - framewise_output.shape[1], 1)\n",
    "    \"\"\"tensor for padding\"\"\"\n",
    "\n",
    "    output = torch.cat((framewise_output, pad), dim=1)\n",
    "    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n",
    "\n",
    "    return output\n",
    "\n",
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "class AttBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\",\n",
    "                 temperature=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.temperature = temperature\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.bn_att = nn.BatchNorm1d(out_features)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "        init_bn(self.bn_att)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_params = {\n",
    "    \"tf_efficientnet_b0_ns\": {\n",
    "        \"features\": 1280,\n",
    "        \"init_op\": partial(tf_efficientnet_b0_ns, pretrained=True, drop_path_rate=0.2)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, lam, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "\n",
    "        \n",
    "    maxes = torch.max(x, 1) \n",
    "    ratio = torch.min(maxes[0]) / maxes[0]\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i] = x[i] * ratio[i]\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEDAudioClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, mel_params, num_classes=SPECIES_NUM):\n",
    "        super().__init__()\n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "        self.interpolate_ratio = 30  # Downsampled ratio\n",
    "        # load pretrained models, using ResNeSt-50 as an example\n",
    "        self.encoder = encoder_params['tf_efficientnet_b0_ns'][\"init_op\"]()\n",
    "\n",
    "        in_features = 1024\n",
    "\n",
    "        self.fc1 = nn.Linear(1280, in_features, bias=True)\n",
    "        self.att_block = AttBlock(in_features, num_classes, activation=\"linear\")\n",
    "        \n",
    "        \n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=mel_params['n_fft'], hop_length=mel_params['hop_length'], \n",
    "            win_length=mel_params['win_length'], window=window, center=center, pad_mode=pad_mode, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=SR, n_fft=mel_params['n_fft'], \n",
    "            n_mels=mel_params['n_mels'], fmin=mel_params['fmin'], fmax=mel_params['fmax'], ref=ref, amin=amin, top_db=top_db, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "            freq_drop_width=8, freq_stripes_num=2)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(mel_params['n_mels'])\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.fc1)\n",
    "        init_bn(self.bn0)\n",
    "\n",
    "    def _add_frequency_encoding(self, x):\n",
    "        n, d, h, w = x.size()\n",
    "\n",
    "        vertical = torch.linspace(-1, 1, w, device=x.device).view(1, 1, 1, -1)\n",
    "        vertical = vertical.repeat(n, 1, h, 1)\n",
    "\n",
    "        return vertical\n",
    "\n",
    "    def _add_time_encoding(self, x):\n",
    "        n, d, h, w = x.size()\n",
    "\n",
    "        horizontal = torch.linspace(-1, 1, h, device=x.device).view(1, 1, -1, 1)\n",
    "        horizontal = horizontal.repeat(n, 1, 1, w)\n",
    "\n",
    "        return horizontal\n",
    "        \n",
    "    def forward(self, x, istrain=True):\n",
    "        \n",
    "        x = self.spectrogram_extractor(x)\n",
    "        # batch_size x 1 x time_steps x freq_bins\n",
    "        x = self.logmel_extractor(x)\n",
    "        # batch_size x 1 x time_steps x mel_bins\n",
    "\n",
    "        frames_num = x.shape[2]\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        freq_encode = self._add_frequency_encoding(x)\n",
    "        time_encode = self._add_time_encoding(x)\n",
    "        x = torch.cat([x, freq_encode, time_encode], dim=1)\n",
    "        \n",
    "        x = self.encoder.forward_features(x)\n",
    "\n",
    "        # Aggregate in frequency axis\n",
    "        x = torch.mean(x, dim=3)\n",
    "\n",
    "        # channel smoothing\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       self.interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            \"framewise_output\": framewise_output,\n",
    "            \"logit\": logit,\n",
    "            \"clipwise_output\": clipwise_output\n",
    "        }\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(mel_params, num_classes=SPECIES_NUM, is_mean_teacher=False):\n",
    "    device = 'cuda'\n",
    "    model = SEDAudioClassifier(mel_params, num_classes=SPECIES_NUM)  \n",
    "    model = model.to(device)\n",
    "    # Detach params for Exponential Moving Average Model (aka the Mean Teacher).\n",
    "    # We'll manually update these params instead of using backprop.\n",
    "    if is_mean_teacher:\n",
    "        for param in model.parameters():\n",
    "            param.detach_()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LitModule(pl.LightningModule):\n",
    "    \n",
    "#     def __init__(self, train_len, mel_params, num_classes=SPECIES_NUM):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.trian_criterion = MeanTeacherLoss()\n",
    "#         self.valid_criterion = bce_criterion\n",
    "#         self.train_len = train_len\n",
    "        \n",
    "#         self.model = get_model(mel_params, num_classes=SPECIES_NUM)\n",
    "#         self.teacher_model = get_model(mel_params, num_classes=SPECIES_NUM, is_mean_teacher=True)\n",
    "#         self.ema_decay = 0.995\n",
    "            \n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=True)\n",
    "#         scheduler = {'scheduler': torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001*0.01),\n",
    "#                                 'name': 'learning_rate',\n",
    "#                                 'interval':'epoch',\n",
    "#                                 'frequency': 1}\n",
    "#         return [optimizer], [scheduler]\n",
    "    \n",
    "#     def update_teacher_params(self, alpha, global_step):\n",
    "#         # Use the true average until the exponential average is more correct\n",
    "#         alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "#         for ema_param, param in zip(self.teacher_model.parameters(), self.model.parameters()):\n",
    "#             ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n",
    "    \n",
    "    \n",
    "#     def training_step(self, train_batch, batch_idx):\n",
    "#         x = train_batch\n",
    "#         y = x['target']\n",
    "#         student_input = x['waveform']\n",
    "#         teacher_input = x['teacher_waveform']\n",
    "#         classif_weights = x['classification_weights']\n",
    "#         batch_size = len(y)\n",
    "        \n",
    "# #         if np.random.uniform() < 0.2:\n",
    "# #             alpha=0.5\n",
    "# #             lam = np.random.beta(alpha, alpha)\n",
    "# #             student_input, y_a, y_b, lam = mixup_data(student_input, y, alpha=alpha)\n",
    "# #             y_pred = self.student_model(student_input, istrain=True)\n",
    "# #             y_pred_t  = self.teacher_model(teacher_input, istrain=True)\n",
    "# #             loss = mixup_criterion(self.trian_criterion, y_pred['clipwise_output'], y_a, y_b, lam)\n",
    "# #         else:\n",
    "#         y_pred = self.model(student_input, istrain=True)\n",
    "#         y_pred_t  = self.teacher_model(teacher_input, istrain=True)\n",
    "# #         loss = self.valid_criterion(y_pred['clipwise_output'], y, isTrain=True)\n",
    "#         loss, class_loss, consistency_loss, consistency_weight = self.trian_criterion(\n",
    "#                         y_pred['clipwise_output'], y_pred_t['clipwise_output'], y, classif_weights, self.current_epoch)\n",
    "#         self.update_teacher_params(self.ema_decay, self.global_step%(self.current_epoch+1))\n",
    "\n",
    "# #             loss = self.trian_criterion(y_pred['clipwise_output'], y)\n",
    "\n",
    "#         self.log('train_loss', loss,  on_epoch=True, prog_bar=True, logger=True)\n",
    "#         return loss\n",
    "    \n",
    "#     def validation_step(self, val_batch, batch_idx):\n",
    "#         x, y = val_batch\n",
    "#         batch_size = len(y)\n",
    "        \n",
    "#         y_pred = self.model(x, istrain=False)\n",
    "#         loss_clip = self.valid_criterion(y_pred['clipwise_output'], y, isTrain=False)\n",
    "#         loss = loss_clip\n",
    "#         y_pred_act = y_pred['clipwise_output']\n",
    "#         lwlap_step, weight_step = lwlap_wrapper(y, y_pred_act)\n",
    "#         lwlap_step = (lwlap_step * weight_step).sum()\n",
    "#         self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "#         self.log('lwlap_score', lwlap_step, on_epoch=True, prog_bar=True, logger=True)\n",
    "#         return loss, lwlap_step\n",
    "\n",
    "#     def validation_epoch_end(self, validation_step_outputs):\n",
    "#         validation_step_outputs = np.array(validation_step_outputs)\n",
    "#         validation_step_losses = validation_step_outputs[:, 0]\n",
    "#         mean_loss = torch.stack([x for x in validation_step_losses]).mean()\n",
    "        \n",
    "#         validation_step_scores = validation_step_outputs[:, 1]\n",
    "#         mean_score = torch.stack([x for x in validation_step_scores]).mean()\n",
    "\n",
    "#         print('valid_epoch_loss = ', mean_loss)\n",
    "#         print('valid_epoch_lwlap = ', mean_score)\n",
    "#         self.log('valid_epoch_loss', mean_loss, prog_bar=True, logger=True)\n",
    "#         self.log('valid_epoch_lwlap', mean_score, prog_bar=True, logger=True)\n",
    "# #         tqdm.write('Dice: \\t%.3f' % mean_loss)\n",
    "\n",
    "#         return mean_loss, mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_metrics(fold, epoch, optimizer, train_loss_metrics, val_loss_metrics):\n",
    "    print(f\"\"\"\n",
    "    {time.ctime()} \\n\n",
    "    Fold:{fold}, Epoch:{epoch}, LR:{optimizer.param_groups[0]['lr']:.7}, Cons. Weight: {train_loss_metrics['consistency_weight']}\\n\n",
    "    --------------------------------------------------------\n",
    "    Metric:              Train    |   Val\n",
    "    --------------------------------------------------------\n",
    "    Loss:                {train_loss_metrics['loss']:0.4f}   |   {val_loss_metrics['loss']:0.4f}\\n\n",
    "    LWLRAP:              {train_loss_metrics['lwlrap']:0.4f}   |   {val_loss_metrics['lwlrap']:0.4f}\\n\n",
    "    Class Loss:          {train_loss_metrics['class_loss']:0.4f}   | \\n\n",
    "    Consistency Loss:    {train_loss_metrics['consistency_loss']:0.4f}   |\\n\n",
    "    --------------------------------------------------------\\n\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id_head_list = []\n",
    "for l_ in train_gby['species_id']:\n",
    "    species_id_head_list.append(l_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class MetricMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.y_true = []\n",
    "        self.y_pred = []\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        try:\n",
    "            self.y_true.extend(y_true.detach().cpu().numpy().tolist())\n",
    "            self.y_pred.extend(torch.sigmoid(y_pred).cpu().detach().numpy().tolist())\n",
    "        except:\n",
    "            print(\"UPDATE FAILURE\")\n",
    "\n",
    "    def update_list(self, y_true, y_pred):\n",
    "        self.y_true.extend(y_true)\n",
    "        self.y_pred.extend(y_pred)\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        score_class, weight = lwlrap(np.array(self.y_true), np.array(self.y_pred))\n",
    "        self.score = (score_class * weight).sum()\n",
    "\n",
    "        return self.score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update teacher to be exponential moving average of student params.\n",
    "def update_teacher_params(student, teacher, alpha, global_step):\n",
    "    # Use the true average until the exponential average is more correct\n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    for ema_param, param in zip(teacher.parameters(), student.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n",
    "\n",
    "\n",
    "def train_one_epoch(student, mean_teacher, loader, \n",
    "                    criterion, optimizer, scheduler, epoch):\n",
    "    global_step = 0\n",
    "    losses = AverageMeter()\n",
    "    consistency_loss_avg = AverageMeter()\n",
    "    class_loss_avg = AverageMeter()\n",
    "    comp_metric = MetricMeter()\n",
    "    device = 'cuda'\n",
    "    ema_decay = 0.995\n",
    "    \n",
    "    student.train()\n",
    "    mean_teacher.train()\n",
    "#     context = nullcontext()\n",
    "    \n",
    "    t = tqdm(loader)\n",
    "    for i, sample in enumerate(t):\n",
    "        student_input = sample['waveform'].to(device)\n",
    "        teacher_input = sample['teacher_waveform'].to(device)\n",
    "        target = sample['target'].to(device)\n",
    "        classif_weights = sample['classification_weights'].to(device)\n",
    "        batch_size = len(target)\n",
    "\n",
    "        student_pred  = student(student_input)\n",
    "        teacher_pred  = mean_teacher(teacher_input)\n",
    "\n",
    "        loss, class_loss, consistency_loss, consistency_weight = criterion(\n",
    "            student_pred['clipwise_output'], teacher_pred['clipwise_output'], target, classif_weights, epoch)\n",
    "\n",
    "#         if not is_val:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        update_teacher_params(student, mean_teacher, \n",
    "                              ema_decay, global_step)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        comp_metric.update(target, student_pred['clipwise_output'])\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        consistency_loss_avg.update(consistency_loss.item(), batch_size)\n",
    "        class_loss_avg.update(class_loss.item(), batch_size)\n",
    "        global_step += 1\n",
    "\n",
    "        t.set_description(f\"Epoch:{epoch} - Loss:{losses.avg:0.4f}\")\n",
    "    t.close()\n",
    "    return {'lwlrap':comp_metric.avg, \n",
    "            'loss':losses.avg, \n",
    "            'consistency_loss':consistency_loss_avg.avg, \n",
    "            'class_loss':class_loss_avg.avg, \n",
    "            'consistency_weight':consistency_weight}\n",
    "\n",
    "\n",
    "def valid_one_epoch(student, mean_teacher, loader, \n",
    "                    criterion, optimizer, scheduler, epoch):\n",
    "    global_step = 0\n",
    "    losses = AverageMeter()\n",
    "    consistency_loss_avg = AverageMeter()\n",
    "    class_loss_avg = AverageMeter()\n",
    "    comp_metric = MetricMeter()\n",
    "    device = 'cuda'\n",
    "    \n",
    "    student.eval()\n",
    "    mean_teacher.eval()\n",
    "    context = torch.no_grad()\n",
    "#     else:\n",
    "#     student.train()\n",
    "#     mean_teacher.train()\n",
    "#     context = nullcontext()\n",
    "    \n",
    "    with context:\n",
    "        t = tqdm(loader)\n",
    "        for i, (sample, y) in enumerate(t):\n",
    "            student_input = sample.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = len(y)\n",
    "\n",
    "            student_pred = student(student_input)\n",
    "#             teacher_pred = mean_teacher(teacher_input)\n",
    "\n",
    "            loss = criterion(torch.sigmoid(student_pred['clipwise_output']), y, isTrain=False)\n",
    "\n",
    "#             loss, class_loss, consistency_loss, consistency_weight = criterion(\n",
    "#                 student_pred['clipwise_output'], teacher_pred['clipwise_output'], target, classif_weights, epoch)\n",
    "\n",
    "            comp_metric.update(y, student_pred['clipwise_output'])\n",
    "            losses.update(loss.item(), batch_size)\n",
    "#             consistency_loss_avg.update(consistency_loss.item(), batch_size)\n",
    "#             class_loss_avg.update(class_loss.item(), batch_size)\n",
    "            global_step += 1\n",
    "\n",
    "            t.set_description(f\"Epoch:{epoch} - Loss:{losses.avg:0.4f}\")\n",
    "        t.close()\n",
    "    return {'lwlrap':comp_metric.avg, \n",
    "            'loss':losses.avg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mel_params, train_loader, val_loader, fold):\n",
    "#     train_df = df[df.fold != fold]\n",
    "#     val_df = df[df.fold == fold]\n",
    "#     train_loader = get_data_loader(train_df, config.train_batch_size, is_val=False)\n",
    "#     val_loader = get_data_loader(val_df, config.valid_batch_size, is_val=True)\n",
    "\n",
    "    student_model = get_model(mel_params, num_classes=SPECIES_NUM)\n",
    "    teacher_model = get_model(mel_params, num_classes=SPECIES_NUM, is_mean_teacher=True)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=0.001)\n",
    "    num_train_steps = int(len(train_loader) * EPOCH)\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001*0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=num_train_steps)\n",
    "    train_criterion = MeanTeacherLoss()\n",
    "    valid_criterion = bce_criterion\n",
    "\n",
    "    best_val_metric = -np.inf\n",
    "    val_metrics = []\n",
    "    train_metrics = []\n",
    "    for epoch in range(0, EPOCH):\n",
    "        train_loss_metrics = train_one_epoch(\n",
    "            student_model, teacher_model, train_loader, \n",
    "            train_criterion, optimizer, scheduler, epoch)\n",
    "        val_loss_metrics = valid_one_epoch(\n",
    "            student_model, teacher_model, val_loader, \n",
    "            valid_criterion, optimizer, scheduler, epoch)\n",
    "\n",
    "        train_metrics.append(train_loss_metrics)\n",
    "        val_metrics.append(val_loss_metrics)\n",
    "        pretty_print_metrics(fold, epoch, optimizer, \n",
    "                             train_loss_metrics, val_loss_metrics)\n",
    "        \n",
    "        if val_loss_metrics['lwlrap'] > best_val_metric:\n",
    "            print(f\"    LWLRAP Improved from {best_val_metric} --> {val_loss_metrics['lwlrap']}\\n\")\n",
    "            torch.save(teacher_model.state_dict(), \n",
    "                       os.path.join(config.save_path, f'fold-{fold}.bin'))\n",
    "            best_val_metric = val_loss_metrics['lwlrap']\n",
    "    return student_model, teacher_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/librosa/filters.py:239: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  \"Empty filters detected in mel frequency basis. \"\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]/home/user/.local/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  \n",
      "Epoch:0 - Loss:7.3587: 100%|██████████| 324/324 [03:45<00:00,  1.43it/s]\n",
      "Epoch:0 - Loss:0.1951: 100%|██████████| 121/121 [00:03<00:00, 36.63it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 19:57:26 2021 \n",
      "\n",
      "    Fold:0, Epoch:0, LR:0.0009990134, Cons. Weight: 0.6737946999085467\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                7.3587   |   0.1951\n",
      "\n",
      "    LWLRAP:              0.2094   |   0.3279\n",
      "\n",
      "    Class Loss:          7.3529   | \n",
      "\n",
      "    Consistency Loss:    0.0059   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from -inf --> 0.3279046927423459\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 - Loss:6.4765: 100%|██████████| 324/324 [03:52<00:00,  1.40it/s]\n",
      "Epoch:1 - Loss:0.1857: 100%|██████████| 121/121 [00:02<00:00, 44.40it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:01:21 2021 \n",
      "\n",
      "    Fold:0, Epoch:1, LR:0.0009960574, Cons. Weight: 0.6805630463993154\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                6.4765   |   0.1857\n",
      "\n",
      "    LWLRAP:              0.2987   |   0.3520\n",
      "\n",
      "    Class Loss:          6.4721   | \n",
      "\n",
      "    Consistency Loss:    0.0044   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.3279046927423459 --> 0.35201177489208735\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2 - Loss:5.9010: 100%|██████████| 324/324 [03:45<00:00,  1.43it/s]\n",
      "Epoch:2 - Loss:0.1523: 100%|██████████| 121/121 [00:02<00:00, 44.59it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:05:09 2021 \n",
      "\n",
      "    Fold:0, Epoch:2, LR:0.0009911436, Cons. Weight: 0.6873925077619901\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                5.9010   |   0.1523\n",
      "\n",
      "    LWLRAP:              0.3506   |   0.5238\n",
      "\n",
      "    Class Loss:          5.8963   | \n",
      "\n",
      "    Consistency Loss:    0.0047   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.35201177489208735 --> 0.5237770068422769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3 - Loss:5.5043: 100%|██████████| 324/324 [03:53<00:00,  1.39it/s]\n",
      "Epoch:3 - Loss:0.1318: 100%|██████████| 121/121 [00:02<00:00, 44.32it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:09:05 2021 \n",
      "\n",
      "    Fold:0, Epoch:3, LR:0.0009842916, Cons. Weight: 0.6942835600114377\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                5.5043   |   0.1318\n",
      "\n",
      "    LWLRAP:              0.4356   |   0.5503\n",
      "\n",
      "    Class Loss:          5.4989   | \n",
      "\n",
      "    Consistency Loss:    0.0054   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.5237770068422769 --> 0.5502991339457962\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4 - Loss:4.9128: 100%|██████████| 324/324 [03:46<00:00,  1.43it/s]\n",
      "Epoch:4 - Loss:0.1219: 100%|██████████| 121/121 [00:02<00:00, 44.27it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:12:55 2021 \n",
      "\n",
      "    Fold:0, Epoch:4, LR:0.0009755283, Cons. Weight: 0.7012366820799585\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                4.9128   |   0.1219\n",
      "\n",
      "    LWLRAP:              0.5393   |   0.6611\n",
      "\n",
      "    Class Loss:          4.9062   | \n",
      "\n",
      "    Consistency Loss:    0.0066   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.5502991339457962 --> 0.6610710009676632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5 - Loss:4.3766: 100%|██████████| 324/324 [03:53<00:00,  1.39it/s]\n",
      "Epoch:5 - Loss:0.1106: 100%|██████████| 121/121 [00:02<00:00, 44.56it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:16:51 2021 \n",
      "\n",
      "    Fold:0, Epoch:5, LR:0.0009648882, Cons. Weight: 0.7082523558272816\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                4.3766   |   0.1106\n",
      "\n",
      "    LWLRAP:              0.6049   |   0.7429\n",
      "\n",
      "    Class Loss:          4.3695   | \n",
      "\n",
      "    Consistency Loss:    0.0071   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.6610710009676632 --> 0.74285960015785\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6 - Loss:4.1156: 100%|██████████| 324/324 [03:47<00:00,  1.42it/s]\n",
      "Epoch:6 - Loss:0.1107: 100%|██████████| 121/121 [00:02<00:00, 44.52it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:20:41 2021 \n",
      "\n",
      "    Fold:0, Epoch:6, LR:0.0009524135, Cons. Weight: 0.7153310660505106\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                4.1156   |   0.1107\n",
      "\n",
      "    LWLRAP:              0.6510   |   0.7046\n",
      "\n",
      "    Class Loss:          4.1085   | \n",
      "\n",
      "    Consistency Loss:    0.0071   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7 - Loss:3.8638: 100%|██████████| 324/324 [03:54<00:00,  1.38it/s]\n",
      "Epoch:7 - Loss:0.1003: 100%|██████████| 121/121 [00:02<00:00, 43.71it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:24:39 2021 \n",
      "\n",
      "    Fold:0, Epoch:7, LR:0.0009381533, Cons. Weight: 0.722473300494024\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.8638   |   0.1003\n",
      "\n",
      "    LWLRAP:              0.6575   |   0.7329\n",
      "\n",
      "    Class Loss:          3.8567   | \n",
      "\n",
      "    Consistency Loss:    0.0071   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8 - Loss:3.4916: 100%|██████████| 324/324 [03:49<00:00,  1.41it/s]\n",
      "Epoch:8 - Loss:0.0942: 100%|██████████| 121/121 [00:02<00:00, 44.53it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:28:31 2021 \n",
      "\n",
      "    Fold:0, Epoch:8, LR:0.000922164, Cons. Weight: 0.7296795498593247\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.4916   |   0.0942\n",
      "\n",
      "    LWLRAP:              0.7020   |   0.7927\n",
      "\n",
      "    Class Loss:          3.4845   | \n",
      "\n",
      "    Consistency Loss:    0.0070   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.74285960015785 --> 0.7926637371703001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9 - Loss:3.4758: 100%|██████████| 324/324 [03:50<00:00,  1.41it/s]\n",
      "Epoch:9 - Loss:0.0905: 100%|██████████| 121/121 [00:02<00:00, 43.66it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:32:25 2021 \n",
      "\n",
      "    Fold:0, Epoch:9, LR:0.0009045085, Cons. Weight: 0.7369503078148391\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.4758   |   0.0905\n",
      "\n",
      "    LWLRAP:              0.7088   |   0.7964\n",
      "\n",
      "    Class Loss:          3.4681   | \n",
      "\n",
      "    Consistency Loss:    0.0077   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.7926637371703001 --> 0.7964170930080021\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:10 - Loss:3.0301: 100%|██████████| 324/324 [03:47<00:00,  1.42it/s]\n",
      "Epoch:10 - Loss:0.0838: 100%|██████████| 121/121 [00:02<00:00, 44.02it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:36:15 2021 \n",
      "\n",
      "    Fold:0, Epoch:10, LR:0.0008852566, Cons. Weight: 0.7442860710056644\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.0301   |   0.0838\n",
      "\n",
      "    LWLRAP:              0.7616   |   0.7946\n",
      "\n",
      "    Class Loss:          3.0229   | \n",
      "\n",
      "    Consistency Loss:    0.0072   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:11 - Loss:3.0370: 100%|██████████| 324/324 [04:03<00:00,  1.33it/s]\n",
      "Epoch:11 - Loss:0.1164: 100%|██████████| 121/121 [00:02<00:00, 44.31it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:40:21 2021 \n",
      "\n",
      "    Fold:0, Epoch:11, LR:0.0008644843, Cons. Weight: 0.7516873390632673\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.0370   |   0.1164\n",
      "\n",
      "    LWLRAP:              0.7611   |   0.7658\n",
      "\n",
      "    Class Loss:          3.0301   | \n",
      "\n",
      "    Consistency Loss:    0.0069   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:12 - Loss:2.9101: 100%|██████████| 324/324 [03:51<00:00,  1.40it/s]\n",
      "Epoch:12 - Loss:0.0803: 100%|██████████| 121/121 [00:02<00:00, 44.71it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:44:16 2021 \n",
      "\n",
      "    Fold:0, Epoch:12, LR:0.0008422736, Cons. Weight: 0.7591546146151242\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.9101   |   0.0803\n",
      "\n",
      "    LWLRAP:              0.7651   |   0.8226\n",
      "\n",
      "    Class Loss:          2.9028   | \n",
      "\n",
      "    Consistency Loss:    0.0073   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.7964170930080021 --> 0.8226045877905382\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:13 - Loss:2.6002: 100%|██████████| 324/324 [03:49<00:00,  1.41it/s]\n",
      "Epoch:13 - Loss:0.0885: 100%|██████████| 121/121 [00:02<00:00, 44.00it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:48:08 2021 \n",
      "\n",
      "    Fold:0, Epoch:13, LR:0.000818712, Cons. Weight: 0.766688403294309\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.6002   |   0.0885\n",
      "\n",
      "    LWLRAP:              0.8001   |   0.8102\n",
      "\n",
      "    Class Loss:          2.5934   | \n",
      "\n",
      "    Consistency Loss:    0.0067   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:14 - Loss:2.7083: 100%|██████████| 324/324 [03:58<00:00,  1.36it/s]\n",
      "Epoch:14 - Loss:0.0756: 100%|██████████| 121/121 [00:02<00:00, 44.49it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:52:09 2021 \n",
      "\n",
      "    Fold:0, Epoch:14, LR:0.0007938926, Cons. Weight: 0.7742892137490264\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.7083   |   0.0756\n",
      "\n",
      "    LWLRAP:              0.7849   |   0.8241\n",
      "\n",
      "    Class Loss:          2.7007   | \n",
      "\n",
      "    Consistency Loss:    0.0075   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8226045877905382 --> 0.824079329761148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:15 - Loss:2.4529: 100%|██████████| 324/324 [03:47<00:00,  1.43it/s]\n",
      "Epoch:15 - Loss:0.0671: 100%|██████████| 121/121 [00:02<00:00, 43.61it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:55:59 2021 \n",
      "\n",
      "    Fold:0, Epoch:15, LR:0.0007679134, Cons. Weight: 0.7819575576520875\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.4529   |   0.0671\n",
      "\n",
      "    LWLRAP:              0.8057   |   0.8443\n",
      "\n",
      "    Class Loss:          2.4458   | \n",
      "\n",
      "    Consistency Loss:    0.0071   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.824079329761148 --> 0.8442683362311141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:16 - Loss:2.3304: 100%|██████████| 324/324 [03:54<00:00,  1.38it/s]\n",
      "Epoch:16 - Loss:0.0803: 100%|██████████| 121/121 [00:02<00:00, 44.50it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 20:59:57 2021 \n",
      "\n",
      "    Fold:0, Epoch:16, LR:0.0007408768, Cons. Weight: 0.7896939497103246\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.3304   |   0.0803\n",
      "\n",
      "    LWLRAP:              0.8289   |   0.8328\n",
      "\n",
      "    Class Loss:          2.3242   | \n",
      "\n",
      "    Consistency Loss:    0.0061   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:17 - Loss:2.2595: 100%|██████████| 324/324 [03:59<00:00,  1.35it/s]\n",
      "Epoch:17 - Loss:0.0704: 100%|██████████| 121/121 [00:02<00:00, 43.84it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:03:59 2021 \n",
      "\n",
      "    Fold:0, Epoch:17, LR:0.0007128896, Cons. Weight: 0.7974989076739534\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.2595   |   0.0704\n",
      "\n",
      "    LWLRAP:              0.8226   |   0.8564\n",
      "\n",
      "    Class Loss:          2.2534   | \n",
      "\n",
      "    Consistency Loss:    0.0061   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8442683362311141 --> 0.8563981473072382\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:18 - Loss:2.0816: 100%|██████████| 324/324 [03:47<00:00,  1.43it/s]\n",
      "Epoch:18 - Loss:0.0661: 100%|██████████| 121/121 [00:02<00:00, 44.40it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:07:49 2021 \n",
      "\n",
      "    Fold:0, Epoch:18, LR:0.0006840623, Cons. Weight: 0.8053729523458644\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.0816   |   0.0661\n",
      "\n",
      "    LWLRAP:              0.8515   |   0.8590\n",
      "\n",
      "    Class Loss:          2.0760   | \n",
      "\n",
      "    Consistency Loss:    0.0056   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8563981473072382 --> 0.8589809410057345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:19 - Loss:2.0685: 100%|██████████| 324/324 [03:52<00:00,  1.39it/s]\n",
      "Epoch:19 - Loss:0.0684: 100%|██████████| 121/121 [00:02<00:00, 44.71it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:11:45 2021 \n",
      "\n",
      "    Fold:0, Epoch:19, LR:0.0006545085, Cons. Weight: 0.8133166075908668\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.0685   |   0.0684\n",
      "\n",
      "    LWLRAP:              0.8397   |   0.8657\n",
      "\n",
      "    Class Loss:          2.0624   | \n",
      "\n",
      "    Consistency Loss:    0.0061   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8589809410057345 --> 0.8657317430044703\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:20 - Loss:2.0769: 100%|██████████| 324/324 [03:59<00:00,  1.35it/s]\n",
      "Epoch:20 - Loss:0.0654: 100%|██████████| 121/121 [00:02<00:00, 44.55it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:15:47 2021 \n",
      "\n",
      "    Fold:0, Epoch:20, LR:0.0006243449, Cons. Weight: 0.821330400344857\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.0769   |   0.0654\n",
      "\n",
      "    LWLRAP:              0.8408   |   0.8721\n",
      "\n",
      "    Class Loss:          2.0707   | \n",
      "\n",
      "    Consistency Loss:    0.0062   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8657317430044703 --> 0.8721368507525533\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:21 - Loss:1.9760: 100%|██████████| 324/324 [03:50<00:00,  1.41it/s]\n",
      "Epoch:21 - Loss:0.0680: 100%|██████████| 121/121 [00:02<00:00, 43.81it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:19:40 2021 \n",
      "\n",
      "    Fold:0, Epoch:21, LR:0.0005936907, Cons. Weight: 0.829414860623932\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.9760   |   0.0680\n",
      "\n",
      "    LWLRAP:              0.8480   |   0.8552\n",
      "\n",
      "    Class Loss:          1.9700   | \n",
      "\n",
      "    Consistency Loss:    0.0059   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:22 - Loss:1.9627: 100%|██████████| 324/324 [03:59<00:00,  1.35it/s]\n",
      "Epoch:22 - Loss:0.0644: 100%|██████████| 121/121 [00:02<00:00, 43.63it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:23:43 2021 \n",
      "\n",
      "    Fold:0, Epoch:22, LR:0.0005626666, Cons. Weight: 0.8375705215334286\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.9627   |   0.0644\n",
      "\n",
      "    LWLRAP:              0.8572   |   0.8586\n",
      "\n",
      "    Class Loss:          1.9569   | \n",
      "\n",
      "    Consistency Loss:    0.0058   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:23 - Loss:1.7967: 100%|██████████| 324/324 [03:54<00:00,  1.38it/s]\n",
      "Epoch:23 - Loss:0.0659: 100%|██████████| 121/121 [00:02<00:00, 44.22it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:27:40 2021 \n",
      "\n",
      "    Fold:0, Epoch:23, LR:0.0005313953, Cons. Weight: 0.8457979192769101\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.7967   |   0.0659\n",
      "\n",
      "    LWLRAP:              0.8578   |   0.8654\n",
      "\n",
      "    Class Loss:          1.7909   | \n",
      "\n",
      "    Consistency Loss:    0.0058   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:24 - Loss:1.7512: 100%|██████████| 324/324 [03:40<00:00,  1.47it/s]\n",
      "Epoch:24 - Loss:0.0629: 100%|██████████| 121/121 [00:02<00:00, 44.22it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:31:24 2021 \n",
      "\n",
      "    Fold:0, Epoch:24, LR:0.0005, Cons. Weight: 0.8540975931650733\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.7512   |   0.0629\n",
      "\n",
      "    LWLRAP:              0.8665   |   0.8615\n",
      "\n",
      "    Class Loss:          1.7450   | \n",
      "\n",
      "    Consistency Loss:    0.0062   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:25 - Loss:1.8038: 100%|██████████| 324/324 [03:51<00:00,  1.40it/s]\n",
      "Epoch:25 - Loss:0.0536: 100%|██████████| 121/121 [00:02<00:00, 44.72it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:35:18 2021 \n",
      "\n",
      "    Fold:0, Epoch:25, LR:0.0004686047, Cons. Weight: 0.8624700856245927\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.8038   |   0.0536\n",
      "\n",
      "    LWLRAP:              0.8681   |   0.8751\n",
      "\n",
      "    Class Loss:          1.7977   | \n",
      "\n",
      "    Consistency Loss:    0.0060   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8721368507525533 --> 0.875107120233518\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:26 - Loss:1.5401: 100%|██████████| 324/324 [03:47<00:00,  1.43it/s]\n",
      "Epoch:26 - Loss:0.0643: 100%|██████████| 121/121 [00:02<00:00, 44.08it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:39:08 2021 \n",
      "\n",
      "    Fold:0, Epoch:26, LR:0.0004373334, Cons. Weight: 0.8709159422068921\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.5401   |   0.0643\n",
      "\n",
      "    LWLRAP:              0.8893   |   0.8752\n",
      "\n",
      "    Class Loss:          1.5346   | \n",
      "\n",
      "    Consistency Loss:    0.0054   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.875107120233518 --> 0.8752133197381131\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:27 - Loss:1.6598: 100%|██████████| 324/324 [04:00<00:00,  1.35it/s]\n",
      "Epoch:27 - Loss:0.0612: 100%|██████████| 121/121 [00:02<00:00, 44.44it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:43:11 2021 \n",
      "\n",
      "    Fold:0, Epoch:27, LR:0.0004063093, Cons. Weight: 0.8794357115968496\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.6598   |   0.0612\n",
      "\n",
      "    LWLRAP:              0.8804   |   0.8712\n",
      "\n",
      "    Class Loss:          1.6541   | \n",
      "\n",
      "    Consistency Loss:    0.0056   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:28 - Loss:1.5549: 100%|██████████| 324/324 [03:47<00:00,  1.42it/s]\n",
      "Epoch:28 - Loss:0.0596: 100%|██████████| 121/121 [00:02<00:00, 44.35it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:47:01 2021 \n",
      "\n",
      "    Fold:0, Epoch:28, LR:0.0003756551, Cons. Weight: 0.888029945621426\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.5549   |   0.0596\n",
      "\n",
      "    LWLRAP:              0.8805   |   0.8725\n",
      "\n",
      "    Class Loss:          1.5493   | \n",
      "\n",
      "    Consistency Loss:    0.0056   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:29 - Loss:1.4591: 100%|██████████| 324/324 [03:52<00:00,  1.40it/s]\n",
      "Epoch:29 - Loss:0.0560: 100%|██████████| 121/121 [00:02<00:00, 44.37it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:50:56 2021 \n",
      "\n",
      "    Fold:0, Epoch:29, LR:0.0003454915, Cons. Weight: 0.8966991992582213\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.4591   |   0.0560\n",
      "\n",
      "    LWLRAP:              0.8808   |   0.8752\n",
      "\n",
      "    Class Loss:          1.4534   | \n",
      "\n",
      "    Consistency Loss:    0.0057   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8752133197381131 --> 0.8752313572561506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:30 - Loss:1.3342: 100%|██████████| 324/324 [04:04<00:00,  1.33it/s]\n",
      "Epoch:30 - Loss:0.0619: 100%|██████████| 121/121 [00:02<00:00, 44.46it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:55:03 2021 \n",
      "\n",
      "    Fold:0, Epoch:30, LR:0.0003159377, Cons. Weight: 0.9054440306439586\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3342   |   0.0619\n",
      "\n",
      "    LWLRAP:              0.8931   |   0.8720\n",
      "\n",
      "    Class Loss:          1.3289   | \n",
      "\n",
      "    Consistency Loss:    0.0053   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:31 - Loss:1.3561: 100%|██████████| 324/324 [03:46<00:00,  1.43it/s]\n",
      "Epoch:31 - Loss:0.0673: 100%|██████████| 121/121 [00:02<00:00, 44.32it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 21:58:52 2021 \n",
      "\n",
      "    Fold:0, Epoch:31, LR:0.0002871104, Cons. Weight: 0.914265001082888\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3561   |   0.0673\n",
      "\n",
      "    LWLRAP:              0.8962   |   0.8720\n",
      "\n",
      "    Class Loss:          1.3503   | \n",
      "\n",
      "    Consistency Loss:    0.0057   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:32 - Loss:1.2470: 100%|██████████| 324/324 [03:52<00:00,  1.39it/s]\n",
      "Epoch:32 - Loss:0.0637: 100%|██████████| 121/121 [00:02<00:00, 44.02it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:02:47 2021 \n",
      "\n",
      "    Fold:0, Epoch:32, LR:0.0002591232, Cons. Weight: 0.9231626750551182\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.2470   |   0.0637\n",
      "\n",
      "    LWLRAP:              0.9080   |   0.8637\n",
      "\n",
      "    Class Loss:          1.2415   | \n",
      "\n",
      "    Consistency Loss:    0.0055   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:33 - Loss:1.1840: 100%|██████████| 324/324 [03:57<00:00,  1.36it/s]\n",
      "Epoch:33 - Loss:0.0620: 100%|██████████| 121/121 [00:02<00:00, 44.09it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:06:48 2021 \n",
      "\n",
      "    Fold:0, Epoch:33, LR:0.0002320866, Cons. Weight: 0.9321376202248648\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1840   |   0.0620\n",
      "\n",
      "    LWLRAP:              0.9150   |   0.8648\n",
      "\n",
      "    Class Loss:          1.1782   | \n",
      "\n",
      "    Consistency Loss:    0.0058   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:34 - Loss:1.3587: 100%|██████████| 324/324 [03:50<00:00,  1.40it/s]\n",
      "Epoch:34 - Loss:0.0624: 100%|██████████| 121/121 [00:02<00:00, 44.74it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:10:41 2021 \n",
      "\n",
      "    Fold:0, Epoch:34, LR:0.0002061074, Cons. Weight: 0.9411904074486235\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3587   |   0.0624\n",
      "\n",
      "    LWLRAP:              0.9022   |   0.8683\n",
      "\n",
      "    Class Loss:          1.3528   | \n",
      "\n",
      "    Consistency Loss:    0.0059   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:35 - Loss:1.2072: 100%|██████████| 324/324 [03:48<00:00,  1.42it/s]\n",
      "Epoch:35 - Loss:0.0588: 100%|██████████| 121/121 [00:02<00:00, 44.54it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:14:33 2021 \n",
      "\n",
      "    Fold:0, Epoch:35, LR:0.000181288, Cons. Weight: 0.9503216107832583\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.2072   |   0.0588\n",
      "\n",
      "    LWLRAP:              0.9105   |   0.8770\n",
      "\n",
      "    Class Loss:          1.2018   | \n",
      "\n",
      "    Consistency Loss:    0.0054   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8752313572561506 --> 0.8770152826971009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:36 - Loss:1.1634: 100%|██████████| 324/324 [03:54<00:00,  1.38it/s]\n",
      "Epoch:36 - Loss:0.0629: 100%|██████████| 121/121 [00:02<00:00, 44.20it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:18:30 2021 \n",
      "\n",
      "    Fold:0, Epoch:36, LR:0.0001577264, Cons. Weight: 0.959531807494012\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1634   |   0.0629\n",
      "\n",
      "    LWLRAP:              0.9113   |   0.8801\n",
      "\n",
      "    Class Loss:          1.1581   | \n",
      "\n",
      "    Consistency Loss:    0.0053   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8770152826971009 --> 0.8801103203017079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:37 - Loss:1.1132: 100%|██████████| 324/324 [03:51<00:00,  1.40it/s]\n",
      "Epoch:37 - Loss:0.0605: 100%|██████████| 121/121 [00:02<00:00, 44.59it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:22:24 2021 \n",
      "\n",
      "    Fold:0, Epoch:37, LR:0.0001355157, Cons. Weight: 0.968821578062429\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1132   |   0.0605\n",
      "\n",
      "    LWLRAP:              0.9229   |   0.8786\n",
      "\n",
      "    Class Loss:          1.1076   | \n",
      "\n",
      "    Consistency Loss:    0.0056   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:38 - Loss:1.1410: 100%|██████████| 324/324 [03:51<00:00,  1.40it/s]\n",
      "Epoch:38 - Loss:0.0595: 100%|██████████| 121/121 [00:02<00:00, 44.39it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:26:18 2021 \n",
      "\n",
      "    Fold:0, Epoch:38, LR:0.0001147434, Cons. Weight: 0.9781915061941923\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1410   |   0.0595\n",
      "\n",
      "    LWLRAP:              0.9123   |   0.8830\n",
      "\n",
      "    Class Loss:          1.1354   | \n",
      "\n",
      "    Consistency Loss:    0.0056   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8801103203017079 --> 0.8829889807162534\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:39 - Loss:1.0779: 100%|██████████| 324/324 [03:58<00:00,  1.36it/s]\n",
      "Epoch:39 - Loss:0.0578: 100%|██████████| 121/121 [00:02<00:00, 44.36it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:30:20 2021 \n",
      "\n",
      "    Fold:0, Epoch:39, LR:9.54915e-05, Cons. Weight: 0.9876421788268842\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.0779   |   0.0578\n",
      "\n",
      "    LWLRAP:              0.9156   |   0.8835\n",
      "\n",
      "    Class Loss:          1.0722   | \n",
      "\n",
      "    Consistency Loss:    0.0057   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8829889807162534 --> 0.8835085369176279\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:40 - Loss:0.9959: 100%|██████████| 324/324 [03:55<00:00,  1.37it/s]\n",
      "Epoch:40 - Loss:0.0589: 100%|██████████| 121/121 [00:02<00:00, 44.14it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:34:18 2021 \n",
      "\n",
      "    Fold:0, Epoch:40, LR:7.783604e-05, Cons. Weight: 0.9971741861376466\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.9959   |   0.0589\n",
      "\n",
      "    LWLRAP:              0.9265   |   0.8804\n",
      "\n",
      "    Class Loss:          0.9904   | \n",
      "\n",
      "    Consistency Loss:    0.0055   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:41 - Loss:0.9286: 100%|██████████| 324/324 [03:50<00:00,  1.41it/s]\n",
      "Epoch:41 - Loss:0.0577: 100%|██████████| 121/121 [00:02<00:00, 44.21it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:38:11 2021 \n",
      "\n",
      "    Fold:0, Epoch:41, LR:6.184666e-05, Cons. Weight: 1.0067881215507624\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.9286   |   0.0577\n",
      "\n",
      "    LWLRAP:              0.9277   |   0.8897\n",
      "\n",
      "    Class Loss:          0.9230   | \n",
      "\n",
      "    Consistency Loss:    0.0056   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8835085369176279 --> 0.8896907385543749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:42 - Loss:0.9629: 100%|██████████| 324/324 [03:57<00:00,  1.36it/s]\n",
      "Epoch:42 - Loss:0.0571: 100%|██████████| 121/121 [00:02<00:00, 44.28it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:42:12 2021 \n",
      "\n",
      "    Fold:0, Epoch:42, LR:4.758647e-05, Cons. Weight: 1.0164845817451402\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.9629   |   0.0571\n",
      "\n",
      "    LWLRAP:              0.9307   |   0.8850\n",
      "\n",
      "    Class Loss:          0.9576   | \n",
      "\n",
      "    Consistency Loss:    0.0053   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:43 - Loss:1.0449: 100%|██████████| 324/324 [03:55<00:00,  1.38it/s]\n",
      "Epoch:43 - Loss:0.0574: 100%|██████████| 121/121 [00:02<00:00, 44.38it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:46:10 2021 \n",
      "\n",
      "    Fold:0, Epoch:43, LR:3.511176e-05, Cons. Weight: 1.026264166661714\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.0449   |   0.0574\n",
      "\n",
      "    LWLRAP:              0.9239   |   0.8831\n",
      "\n",
      "    Class Loss:          1.0396   | \n",
      "\n",
      "    Consistency Loss:    0.0053   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:44 - Loss:0.8829: 100%|██████████| 324/324 [03:55<00:00,  1.38it/s]\n",
      "Epoch:44 - Loss:0.0569: 100%|██████████| 121/121 [00:02<00:00, 44.51it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:50:08 2021 \n",
      "\n",
      "    Fold:0, Epoch:44, LR:2.447174e-05, Cons. Weight: 1.0361274795107456\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.8829   |   0.0569\n",
      "\n",
      "    LWLRAP:              0.9366   |   0.8883\n",
      "\n",
      "    Class Loss:          0.8776   | \n",
      "\n",
      "    Consistency Loss:    0.0053   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:45 - Loss:0.8870: 100%|██████████| 324/324 [03:51<00:00,  1.40it/s]\n",
      "Epoch:45 - Loss:0.0571: 100%|██████████| 121/121 [00:02<00:00, 44.63it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:54:02 2021 \n",
      "\n",
      "    Fold:0, Epoch:45, LR:1.570842e-05, Cons. Weight: 1.046075126779031\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.8870   |   0.0571\n",
      "\n",
      "    LWLRAP:              0.9410   |   0.8863\n",
      "\n",
      "    Class Loss:          0.8818   | \n",
      "\n",
      "    Consistency Loss:    0.0052   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:46 - Loss:0.9007: 100%|██████████| 324/324 [04:02<00:00,  1.34it/s]\n",
      "Epoch:46 - Loss:0.0567: 100%|██████████| 121/121 [00:02<00:00, 44.60it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 22:58:07 2021 \n",
      "\n",
      "    Fold:0, Epoch:46, LR:8.856375e-06, Cons. Weight: 1.0561077182370224\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.9007   |   0.0567\n",
      "\n",
      "    LWLRAP:              0.9280   |   0.8958\n",
      "\n",
      "    Class Loss:          0.8955   | \n",
      "\n",
      "    Consistency Loss:    0.0052   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8896907385543749 --> 0.8958120162665617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:47 - Loss:0.8612: 100%|██████████| 324/324 [04:01<00:00,  1.34it/s]\n",
      "Epoch:47 - Loss:0.0571: 100%|██████████| 121/121 [00:02<00:00, 44.63it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 23:02:11 2021 \n",
      "\n",
      "    Fold:0, Epoch:47, LR:3.942649e-06, Cons. Weight: 1.0662258669458402\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.8612   |   0.0571\n",
      "\n",
      "    LWLRAP:              0.9339   |   0.8901\n",
      "\n",
      "    Class Loss:          0.8558   | \n",
      "\n",
      "    Consistency Loss:    0.0054   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:48 - Loss:0.9085: 100%|██████████| 324/324 [03:55<00:00,  1.37it/s]\n",
      "Epoch:48 - Loss:0.0571: 100%|██████████| 121/121 [00:02<00:00, 44.01it/s]\n",
      "  0%|          | 0/324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 23:06:10 2021 \n",
      "\n",
      "    Fold:0, Epoch:48, LR:9.866358e-07, Cons. Weight: 1.0764301892641972\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.9085   |   0.0571\n",
      "\n",
      "    LWLRAP:              0.9325   |   0.8906\n",
      "\n",
      "    Class Loss:          0.9030   | \n",
      "\n",
      "    Consistency Loss:    0.0055   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:49 - Loss:0.8925: 100%|██████████| 324/324 [03:53<00:00,  1.39it/s]\n",
      "Epoch:49 - Loss:0.0574: 100%|██████████| 121/121 [00:02<00:00, 44.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 23:10:06 2021 \n",
      "\n",
      "    Fold:0, Epoch:49, LR:0.0, Cons. Weight: 1.086721304855215\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.8925   |   0.0574\n",
      "\n",
      "    LWLRAP:              0.9257   |   0.8784\n",
      "\n",
      "    Class Loss:          0.8873   | \n",
      "\n",
      "    Consistency Loss:    0.0052   |\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e8a6adcefbb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'melspectrogram_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#     model = LitModule(train_len, config['dataset']['params']['melspectrogram_parameters'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-104478520ca2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(mel_params, train_loader, val_loader, fold)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#                        os.path.join(config.save_path, f'fold-{fold}.bin'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mbest_val_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loss_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lwlrap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_gby, species_id_head_list)):\n",
    "    # Picking only first fold to train/val on\n",
    "    # This means loss of 20% training data\n",
    "    # To avoid this, you can train 5 different models on 5 folds and average predictions\n",
    "    train_data = train_df[~train_df['name'].isin(train_gby.iloc[val_index]['name'])]\n",
    "    valid_data = train_df[train_df['name'].isin(train_gby.iloc[val_index]['name'])]    \n",
    "    \n",
    "    train_data.reset_index(inplace=True, drop=True)\n",
    "    valid_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    train_dataset = SpectrogramTrainDataset(train_data, config[\"dataset\"][\"params\"])\n",
    "    valid_dataset = SpectrogramValidDataset(valid_data, config[\"dataset\"][\"params\"])\n",
    "    \n",
    "    train_loader = data.DataLoader(train_dataset, **config[\"loader\"][\"train\"])\n",
    "    valid_loader = data.DataLoader(valid_dataset, **config[\"loader\"][\"valid\"])\n",
    "    \n",
    "    train_len = len(train_loader)\n",
    "    \n",
    "    student_model, teacher_model = train(config['dataset']['params']['melspectrogram_parameters'], train_loader, valid_loader, fold_id)\n",
    "        \n",
    "#     model = LitModule(train_len, config['dataset']['params']['melspectrogram_parameters'])\n",
    "    \n",
    "#     trainer = pl.Trainer(\n",
    "#         max_epochs=EPOCH,\n",
    "#         default_root_dir=OUTPUT_DIR,\n",
    "#         gpus=1,\n",
    "# #         callbacks=[TrainCallback],\n",
    "#         deterministic=True,\n",
    "#         benchmark=True\n",
    "#     )\n",
    "#     trainer.fit(model, train_loader, valid_loader)\n",
    "    \n",
    "    break\n",
    "    \n",
    "    torch.save(model.state_dict(), OUTPUT_DIR + 'model' + str(fold_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), OUTPUT_DIR + 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "layers = list(base_model.children())[:-1]\n",
    "\n",
    "in_features = base_model.fc.in_features\n",
    "in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3f786850e387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
