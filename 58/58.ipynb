{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch==1.6.0\n",
      "  Downloading torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 748.8 MB 16 kB/s \n",
      "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0) (0.18.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0) (1.17.4)\n",
      "Installing collected packages: torch\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx and convert-onnx-to-caffe2 are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed torch-1.6.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.1.48-cp36-cp36m-manylinux2014_x86_64.whl (50.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 50.4 MB 4.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.17.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.1.48\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision==0.7.0 in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
      "Requirement already satisfied: torch==1.6.0 in /home/user/.local/lib/python3.6/site-packages (from torchvision==0.7.0) (1.6.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0) (1.17.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0) (7.2.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchvision==0.7.0) (0.18.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-0.5.2-py3-none-any.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 1.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.1.0)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.5.1.48-cp36-cp36m-manylinux2014_x86_64.whl (37.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.6 MB 20.4 MB/s \n",
      "\u001b[?25hCollecting scikit-image>=0.16.1\n",
      "  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 12.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations) (5.3.1)\n",
      "Collecting imgaug>=0.4.0\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "\u001b[K     |████████████████████████████████| 948 kB 20.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.17.4)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5)\n",
      "Collecting imageio>=2.3.0\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 6.0 MB/s \n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 6.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (7.2.0)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 4.6 MB/s \n",
      "\u001b[?25hCollecting matplotlib!=3.0.0,>=2.0.0\n",
      "  Downloading matplotlib-3.3.3-cp36-cp36m-manylinux1_x86_64.whl (11.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.6 MB 10.4 MB/s \n",
      "\u001b[?25hCollecting Shapely\n",
      "  Downloading Shapely-1.7.1-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 18.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (1.11.0)\n",
      "Requirement already satisfied: opencv-python in /home/user/.local/lib/python3.6/site-packages (from imgaug>=0.4.0->albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.2.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.7.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (49.6.0)\n",
      "Installing collected packages: opencv-python-headless, imageio, tifffile, PyWavelets, matplotlib, scikit-image, Shapely, imgaug, albumentations\n",
      "\u001b[33m  WARNING: The scripts imageio_download_bin and imageio_remove_bin are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts lsm2bin and tifffile are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script skivi is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed PyWavelets-1.1.1 Shapely-1.7.1 albumentations-0.5.2 imageio-2.9.0 imgaug-0.4.0 matplotlib-3.3.3 opencv-python-headless-4.5.1.48 scikit-image-0.17.2 tifffile-2020.9.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 394.7 MB 23 kB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 6.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 9.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 4.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 18.2 MB/s \n",
      "\u001b[?25hCollecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 5.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
      "Collecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 1.7 MB/s \n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 14.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (49.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (3.2.2)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 28.3 MB/s \n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.10)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (1.7.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 12.6 MB/s \n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 6.7 MB/s \n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 15.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 6.8 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: wrapt\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=66069 sha256=9fc1fc5aa7204ffda4d427925a8f80eea05430c0fa22d89c027dab4c8fce4e8a\n",
      "  Stored in directory: /home/user/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "Successfully built wrapt\n",
      "Installing collected packages: tensorflow-estimator, six, protobuf, numpy, wheel, gast, astunparse, flatbuffers, grpcio, wrapt, opt-einsum, oauthlib, requests-oauthlib, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, google-auth-oauthlib, tensorboard-plugin-wit, tensorboard, tensorflow\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.6 are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script wheel is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "umap-learn 0.4.6 requires scipy>=1.3.1, but you'll have scipy 1.1.0 which is incompatible.\n",
      "tensorflow-gpu 1.12.0 requires tensorboard<1.13.0,>=1.12.0, but you'll have tensorboard 2.4.0 which is incompatible.\n",
      "imbalanced-learn 0.7.0 requires scikit-learn>=0.23, but you'll have scikit-learn 0.20.0 which is incompatible.\u001b[0m\n",
      "Successfully installed astunparse-1.6.3 cachetools-4.2.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.24.0 google-auth-oauthlib-0.4.2 grpcio-1.32.0 numpy-1.19.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 six-1.15.0 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 wheel-0.36.2 wrapt-1.12.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.1.3-py3-none-any.whl (680 kB)\n",
      "\u001b[K     |████████████████████████████████| 680 kB 6.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (5.3.1)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/user/.local/lib/python3.6/site-packages (from pytorch-lightning) (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (4.48.2)\n",
      "Collecting fsspec[http]>=0.8.1\n",
      "  Downloading fsspec-0.8.5-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 2.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3 in /home/user/.local/lib/python3.6/site-packages (from pytorch-lightning) (1.6.0)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (0.18.2)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/user/.local/lib/python3.6/site-packages (from pytorch-lightning) (1.19.5)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.2.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.7.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.14.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.24.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.32.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (49.6.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/user/.local/lib/python3.6/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
      "Collecting aiohttp; extra == \"http\"\n",
      "  Downloading aiohttp-3.7.3-cp36-cp36m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 1.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/user/.local/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/user/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/user/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (2.10)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp36-cp36m-manylinux2014_x86_64.whl (293 kB)\n",
      "\u001b[K     |████████████████████████████████| 293 kB 2.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (3.7.4.3)\n",
      "Collecting idna-ssl>=1.0; python_version < \"3.7\"\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp36-cp36m-manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[K     |████████████████████████████████| 141 kB 2.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (20.1.0)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/user/.local/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/user/.local/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Building wheels for collected packages: idna-ssl\n",
      "  Building wheel for idna-ssl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3160 sha256=28f4ae2b9d0c95bf497b48c4178496a0488455d2eca817cf939d34dcbec670b8\n",
      "  Stored in directory: /home/user/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\n",
      "Successfully built idna-ssl\n",
      "Installing collected packages: multidict, yarl, idna-ssl, async-timeout, aiohttp, fsspec, pytorch-lightning\n",
      "Successfully installed aiohttp-3.7.3 async-timeout-3.0.1 fsspec-0.8.5 idna-ssl-1.1.0 multidict-5.1.0 pytorch-lightning-1.1.3 yarl-1.6.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.6.0\n",
    "!pip install opencv-python\n",
    "!pip install torchvision==0.7.0\n",
    "!pip install albumentations\n",
    "!pip install tensorflow\n",
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting audiomentations\n",
      "  Downloading audiomentations-0.15.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: scipy<2,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from audiomentations) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.0 in /home/user/.local/lib/python3.6/site-packages (from audiomentations) (1.19.5)\n",
      "Requirement already satisfied: librosa<=0.8.0,>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from audiomentations) (0.8.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (2.1.8)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.6/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (1.1.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.2.2)\n",
      "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.48.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (4.4.2)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.20.0)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.10.3.post1)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.6/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.16.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.24.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (20.4)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (1.4.4)\n",
      "Requirement already satisfied: six>=1.3 in /home/user/.local/lib/python3.6/site-packages (from resampy>=0.2.2->librosa<=0.8.0,>=0.6.1->audiomentations) (1.15.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa<=0.8.0,>=0.6.1->audiomentations) (0.31.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa<=0.8.0,>=0.6.1->audiomentations) (49.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa<=0.8.0,>=0.6.1->audiomentations) (1.14.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.2.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.20)\n",
      "Installing collected packages: audiomentations\n",
      "Successfully installed audiomentations-0.15.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import typing as tp\n",
    "import yaml\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "# import resnest.torch as resnest_torch\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "# from resnet import ResNet, Bottleneck\n",
    "\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "import albumentations as A\n",
    "import audiomentations as AA\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_set = {\n",
    "    'dataset': {\n",
    "          'name': 'SpectrogramDataset',\n",
    "          'params': {\n",
    "            'img_size': 224, \n",
    "            'melspectrogram_parameters': {\n",
    "              'n_mels': 128, \n",
    "              'fmin': 50, \n",
    "              'fmax': 15000, \n",
    "            }\n",
    "      }\n",
    "    },\n",
    "    'loader': {\n",
    "      'train': {\n",
    "        'batch_size': 6,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 2,\n",
    "        'pin_memory': True,\n",
    "        'drop_last': True,\n",
    "      },\n",
    "      'valid': {\n",
    "        'batch_size': 2,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 2,\n",
    "        'pin_memory': True,\n",
    "        'drop_last': True,\n",
    "      }\n",
    "    }\n",
    "}\n",
    "SEED=1213\n",
    "PERIOD = 5\n",
    "OK_RANGE = 60\n",
    "SPECIES_NUM = 24\n",
    "EPOCH = 80\n",
    "OUTPUT_DIR = './output/'\n",
    "HOP_LEN = 512\n",
    "SR = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_ROOT = Path(\"/home/knikaido/work/Rainforest-Connection/data\")\n",
    "RAW_DATA = INPUT_ROOT / \"rfcx-species-audio-detection\"\n",
    "TRAIN_AUDIO_DIR = RAW_DATA / \"train\"\n",
    "# TRAIN_RESAMPLED_AUDIO_DIRS = [\n",
    "#   INPUT_ROOT / \"birdsong-resampled-train-audio-{:0>2}\".format(i)  for i in range(5)\n",
    "# ]\n",
    "TEST_AUDIO_DIR = RAW_DATA / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioTransform(BasicTransform):\n",
    "    \"\"\" Transform for audio task. This is the main class where we override the targets and update params function for our need\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "    \n",
    "class PitchShift(AudioTransform):\n",
    "    \"\"\" Do time shifting of audio \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5 , n_steps=None):\n",
    "        super(PitchShift, self).__init__(always_apply, p)\n",
    "        '''\n",
    "        nsteps here is equal to number of semitones\n",
    "        '''\n",
    "        \n",
    "        self.n_steps = n_steps\n",
    "        \n",
    "    def apply(self,data,**params):\n",
    "        '''\n",
    "        data : ndarray of audio timeseries\n",
    "        '''        \n",
    "        return librosa.effects.pitch_shift(data,sr=SR,n_steps=self.n_steps)\n",
    "    \n",
    "class AddGaussianNoise(AudioTransform):\n",
    "    \"\"\" Do time shifting of audio \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(AddGaussianNoise, self).__init__(always_apply, p)\n",
    "        \n",
    "        \n",
    "    def apply(self,data,**params):\n",
    "        '''\n",
    "        data : ndarray of audio timeseries\n",
    "        ''' \n",
    "        noise = np.random.randn(len(data))\n",
    "        data_wn = data + 0.05*noise\n",
    "        return data_wn\n",
    "    \n",
    "class NoAugment(AudioTransform):\n",
    "    \"\"\" Do time shifting of audio \"\"\"\n",
    "    def __init__(self, always_apply=False):\n",
    "        super(NoAugment, self).__init__(always_apply)\n",
    "        \n",
    "        \n",
    "    def apply(self,data,**params):\n",
    "        '''\n",
    "        data : ndarray of audio timeseries\n",
    "        ''' \n",
    "        return data\n",
    "    \n",
    "def get_augmentation():\n",
    "    train_transform = [\n",
    "#         PitchShift(p=1.0,n_steps=4),\n",
    "        AddGaussianNoise(p=0.2),\n",
    "    ]\n",
    "    return A.OneOf(train_transform)  # <- Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_transform = AA.Compose([\n",
    "    AA.AddGaussianNoise(p=0.2, min_amplitude=0.05, max_amplitude=0.05),\n",
    "#     AA.AddGaussianSNR(p=0.2),\n",
    "    #AA.AddBackgroundNoise(\"../input/train_audio/\", p=1)\n",
    "    #AA.AddImpulseResponse(p=0.1),\n",
    "    #AA.AddShortNoises(\"../input/train_audio/\", p=1)\n",
    "    #AA.FrequencyMask(min_frequency_band=0.0,  max_frequency_band=0.2, p=0.1),\n",
    "    #AA.TimeMask(min_band_part=0.0, max_band_part=0.2, p=0.1),\n",
    "    #AA.PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.1),\n",
    "    #AA.Shift(p=0.1),\n",
    "    #AA.Normalize(p=0.1),\n",
    "    #AA.ClippingDistortion(min_percentile_threshold=0, max_percentile_threshold=1, p=0.05),\n",
    "    #AA.PolarityInversion(p=0.05),\n",
    "    #AA.Gain(p=0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>songtype_id</th>\n",
       "      <th>t_min</th>\n",
       "      <th>f_min</th>\n",
       "      <th>t_max</th>\n",
       "      <th>f_max</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003bec244</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>44.5440</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.1307</td>\n",
       "      <td>5531.25</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006ab765f</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39.9615</td>\n",
       "      <td>7235.160</td>\n",
       "      <td>46.0452</td>\n",
       "      <td>11283.40</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007f87ba2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>39.1360</td>\n",
       "      <td>562.500</td>\n",
       "      <td>42.2720</td>\n",
       "      <td>3281.25</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0099c367b</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>51.4206</td>\n",
       "      <td>1464.260</td>\n",
       "      <td>55.1996</td>\n",
       "      <td>4565.04</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009b760e6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0854</td>\n",
       "      <td>947.461</td>\n",
       "      <td>52.5293</td>\n",
       "      <td>10852.70</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>fe8d9ac40</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>53.4720</td>\n",
       "      <td>93.750</td>\n",
       "      <td>54.0960</td>\n",
       "      <td>843.75</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>fea6b438a</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>43.5787</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.7653</td>\n",
       "      <td>4031.25</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>ff2eb9ce5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2267</td>\n",
       "      <td>5906.250</td>\n",
       "      <td>16.0213</td>\n",
       "      <td>8250.00</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>ffb8d8391</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14.3467</td>\n",
       "      <td>4781.250</td>\n",
       "      <td>16.6987</td>\n",
       "      <td>10406.20</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>ffb9a7b9a</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>40.3200</td>\n",
       "      <td>3187.500</td>\n",
       "      <td>41.0133</td>\n",
       "      <td>5062.50</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1216 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     recording_id  species_id  songtype_id    t_min     f_min    t_max  \\\n",
       "0       003bec244          14            1  44.5440  2531.250  45.1307   \n",
       "1       006ab765f          23            1  39.9615  7235.160  46.0452   \n",
       "2       007f87ba2          12            1  39.1360   562.500  42.2720   \n",
       "3       0099c367b          17            4  51.4206  1464.260  55.1996   \n",
       "4       009b760e6          10            1  50.0854   947.461  52.5293   \n",
       "...           ...         ...          ...      ...       ...      ...   \n",
       "1211    fe8d9ac40          13            1  53.4720    93.750  54.0960   \n",
       "1212    fea6b438a           4            1  43.5787  2531.250  45.7653   \n",
       "1213    ff2eb9ce5           0            1  15.2267  5906.250  16.0213   \n",
       "1214    ffb8d8391           5            1  14.3467  4781.250  16.6987   \n",
       "1215    ffb9a7b9a          18            1  40.3200  3187.500  41.0133   \n",
       "\n",
       "         f_max                                               name  \n",
       "0      5531.25  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1     11283.40  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "2      3281.25  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "3      4565.04  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "4     10852.70  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "...        ...                                                ...  \n",
       "1211    843.75  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1212   4031.25  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1213   8250.00  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1214  10406.20  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1215   5062.50  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "\n",
       "[1216 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_pickle(RAW_DATA / \"train_gby_wav_raw.pkl\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>songtype_id</th>\n",
       "      <th>t_min</th>\n",
       "      <th>f_min</th>\n",
       "      <th>t_max</th>\n",
       "      <th>f_max</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003bec244</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[44.544]</td>\n",
       "      <td>[2531.25]</td>\n",
       "      <td>[45.1307]</td>\n",
       "      <td>[5531.25]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006ab765f</td>\n",
       "      <td>[23]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[39.9615]</td>\n",
       "      <td>[7235.16]</td>\n",
       "      <td>[46.0452]</td>\n",
       "      <td>[11283.4]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007f87ba2</td>\n",
       "      <td>[12]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[39.135999999999996]</td>\n",
       "      <td>[562.5]</td>\n",
       "      <td>[42.272]</td>\n",
       "      <td>[3281.25]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0099c367b</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[51.4206]</td>\n",
       "      <td>[1464.26]</td>\n",
       "      <td>[55.1996]</td>\n",
       "      <td>[4565.04]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009b760e6</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[50.0854]</td>\n",
       "      <td>[947.461]</td>\n",
       "      <td>[52.5293]</td>\n",
       "      <td>[10852.7]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>fe8d9ac40</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[53.472]</td>\n",
       "      <td>[93.75]</td>\n",
       "      <td>[54.096000000000004]</td>\n",
       "      <td>[843.75]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>fea6b438a</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[43.5787]</td>\n",
       "      <td>[2531.25]</td>\n",
       "      <td>[45.7653]</td>\n",
       "      <td>[4031.25]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>ff2eb9ce5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[15.2267]</td>\n",
       "      <td>[5906.25]</td>\n",
       "      <td>[16.0213]</td>\n",
       "      <td>[8250.0]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>ffb8d8391</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[14.3467]</td>\n",
       "      <td>[4781.25]</td>\n",
       "      <td>[16.6987]</td>\n",
       "      <td>[10406.2]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>ffb9a7b9a</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[40.32]</td>\n",
       "      <td>[3187.5]</td>\n",
       "      <td>[41.0133]</td>\n",
       "      <td>[5062.5]</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1132 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     recording_id species_id songtype_id                 t_min      f_min  \\\n",
       "0       003bec244       [14]         [1]              [44.544]  [2531.25]   \n",
       "1       006ab765f       [23]         [1]             [39.9615]  [7235.16]   \n",
       "2       007f87ba2       [12]         [1]  [39.135999999999996]    [562.5]   \n",
       "3       0099c367b       [17]         [4]             [51.4206]  [1464.26]   \n",
       "4       009b760e6       [10]         [1]             [50.0854]  [947.461]   \n",
       "...           ...        ...         ...                   ...        ...   \n",
       "1127    fe8d9ac40       [13]         [1]              [53.472]    [93.75]   \n",
       "1128    fea6b438a        [4]         [1]             [43.5787]  [2531.25]   \n",
       "1129    ff2eb9ce5        [0]         [1]             [15.2267]  [5906.25]   \n",
       "1130    ffb8d8391        [5]         [1]             [14.3467]  [4781.25]   \n",
       "1131    ffb9a7b9a       [18]         [1]               [40.32]   [3187.5]   \n",
       "\n",
       "                     t_max      f_max  \\\n",
       "0                [45.1307]  [5531.25]   \n",
       "1                [46.0452]  [11283.4]   \n",
       "2                 [42.272]  [3281.25]   \n",
       "3                [55.1996]  [4565.04]   \n",
       "4                [52.5293]  [10852.7]   \n",
       "...                    ...        ...   \n",
       "1127  [54.096000000000004]   [843.75]   \n",
       "1128             [45.7653]  [4031.25]   \n",
       "1129             [16.0213]   [8250.0]   \n",
       "1130             [16.6987]  [10406.2]   \n",
       "1131             [41.0133]   [5062.5]   \n",
       "\n",
       "                                                   name  \n",
       "0     /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1     /home/knikaido/work/Rainforest-Connection/data...  \n",
       "2     /home/knikaido/work/Rainforest-Connection/data...  \n",
       "3     /home/knikaido/work/Rainforest-Connection/data...  \n",
       "4     /home/knikaido/work/Rainforest-Connection/data...  \n",
       "...                                                 ...  \n",
       "1127  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1128  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1129  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1130  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1131  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "\n",
       "[1132 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gby = pd.read_pickle(RAW_DATA / \"train_gby.pkl\")\n",
    "train_gby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(\n",
    "    X: np.ndarray, mean=None, std=None,\n",
    "    norm_max=None, norm_min=None, eps=1e-6\n",
    "):\n",
    "    # Stack X as [X,X,X]\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    X = X - mean\n",
    "    std = std or X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Normalize to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramTrainDataset(data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gby_df: pd.DataFrame,\n",
    "        setting: tp.Dict\n",
    "    ):\n",
    "        self.img_size = setting['img_size']\n",
    "        self.melspectrogram_parameters = setting['melspectrogram_parameters']\n",
    "#         self.transform = get_augmentation()\n",
    "        self.audio_transform = train_audio_transform\n",
    "        \n",
    "        self.gby_df = gby_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gby_df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \n",
    "        wav_path = self.gby_df['name'][idx]\n",
    "        train_element = self.gby_df.iloc[idx]\n",
    "        \n",
    "        y, sr = sf.read(wav_path)\n",
    "    \n",
    "        len_y = len(y)\n",
    "        effective_length = sr * PERIOD\n",
    "\n",
    "        tmin = int(SR * train_element['t_min'])\n",
    "        tmax = int(SR * train_element['t_max'])\n",
    "        \n",
    "        #時間かかる\n",
    "        tgt_len = int(tmax - tmin) \n",
    "        if(effective_length < tgt_len):\n",
    "            start = int(max(0.0, min(tmin - (effective_length - tgt_len) / 2, min(tmax + (effective_length - tgt_len) / 2, len_y) - effective_length)))\n",
    "            end = start + effective_length\n",
    "        else:\n",
    "            while(1):\n",
    "                start = np.random.randint(len_y - effective_length)\n",
    "                end = start + effective_length\n",
    "                tgt_len = int((tmax - tmin) * OK_RANGE / 100)\n",
    "                if( (start < tmin and tmin + tgt_len < end) or (start < tmax - tgt_len and tmax < end) ):\n",
    "                    break\n",
    "        \n",
    "#         start = np.random.randint(len_y - effective_length)\n",
    "#         end = start + effective_length\n",
    "\n",
    "        \n",
    "        y = y[start:end].astype(np.float32)\n",
    "        y = self.audio_transform(samples=y, sample_rate=sr)\n",
    "#         y = self.transform(data=y)['data']\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "        \n",
    "        label = np.zeros(SPECIES_NUM, dtype=\"f\")\n",
    "        label[train_element['species_id']] = 1\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "class SpectrogramValidDataset(data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gby_df: pd.DataFrame,\n",
    "        setting: tp.Dict\n",
    "    ):\n",
    "        self.img_size = setting['img_size']\n",
    "        self.melspectrogram_parameters = setting['melspectrogram_parameters']\n",
    "        \n",
    "        self.gby_df = gby_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gby_df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \n",
    "        wav_path = self.gby_df['name'][idx]\n",
    "        train_element = self.gby_df.iloc[idx]\n",
    "        \n",
    "        y, sr = sf.read(wav_path)\n",
    "        \n",
    "        len_y = len(y)\n",
    "        effective_length = sr * PERIOD\n",
    "\n",
    "        tmin = int(SR * train_element['t_min'])\n",
    "        tmax = int(SR * train_element['t_max'])\n",
    "        \n",
    "        #時間かかる\n",
    "        while(1):\n",
    "            start = np.random.randint(len_y - effective_length)\n",
    "            end = start + effective_length\n",
    "            tgt_len = int((tmax - tmin) * 50 / 100)\n",
    "            if( (start < tmin and tmin + tgt_len < end) or (start < tmax - tgt_len and tmax < end) ):\n",
    "                break\n",
    "        \n",
    "        y = y[start:end].astype(np.float32)\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "        \n",
    "        label = np.zeros(SPECIES_NUM, dtype=\"f\")\n",
    "        label[train_element['species_id']] = 1\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion():\n",
    "    pos_weights = torch.ones(SPECIES_NUM)\n",
    "    pos_weights = pos_weights * SPECIES_NUM\n",
    "#     loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "    loss_function = nn.BCELoss()\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='valid_epoch_lwlap',\n",
    "   min_delta=0.00,\n",
    "   patience=5,\n",
    "   verbose=True,\n",
    "   mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4167)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "def lwlrap(truth, scores):\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = _one_sample_positive_class_precisions(scores[sample_num, :], truth[sample_num, :])\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = precision_at_hits\n",
    "\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    return per_class_lwlrap, weight_per_class\n",
    "\n",
    "def lwlap_wrapper(y_true, y_score):\n",
    "    y_true = y_true.to('cpu').detach().numpy().copy()\n",
    "    y_score = y_score.to('cpu').detach().numpy().copy()\n",
    "    score_class, weight = lwlrap(y_true, y_score)\n",
    "    score_class = torch.from_numpy(score_class.astype(np.float32)).clone()\n",
    "    weight = torch.from_numpy(weight.astype(np.float32)).clone()\n",
    "    return score_class, weight\n",
    "\n",
    "y_true = np.array([[1, 0, 0], [0, 0, 1]])\n",
    "y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])\n",
    "y_true = torch.from_numpy(y_true.astype(np.float32)).clone()\n",
    "y_score = torch.from_numpy(y_score.astype(np.float32)).clone()\n",
    "\n",
    "score_class, weight = lwlap_wrapper(y_true, y_score)\n",
    "score = (score_class * weight).sum()\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    pad = framewise_output[:, -1:, :].repeat(\n",
    "        1, frames_num - framewise_output.shape[1], 1)\n",
    "    \"\"\"tensor for padding\"\"\"\n",
    "\n",
    "    output = torch.cat((framewise_output, pad), dim=1)\n",
    "    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n",
    "\n",
    "    return output\n",
    "\n",
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "class AttBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\",\n",
    "                 temperature=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.temperature = temperature\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.bn_att = nn.BatchNorm1d(out_features)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "        init_bn(self.bn_att)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.clamp(self.att(x), -10, 10), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModule(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, num_classes=SPECIES_NUM):\n",
    "        super().__init__()\n",
    "        self.interpolate_ratio = 30  # Downsampled ratio\n",
    "        # load pretrained models, using ResNeSt-50 as an example\n",
    "        base_model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n",
    "        layers = list(base_model.children())[:-2]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "        in_features = base_model.fc.in_features\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n",
    "        self.att_block = AttBlock(in_features, num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        self.init_weight()\n",
    "        self.criterion = get_criterion()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.fc1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        frames_num = input.size(3)\n",
    "\n",
    "        # (batch_size, channels, freq, frames)\n",
    "        x = self.encoder(input)\n",
    "\n",
    "        # (batch_size, channels, frames)\n",
    "        x = torch.mean(x, dim=2)\n",
    "\n",
    "        # channel smoothing\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       self.interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            \"framewise_output\": framewise_output,\n",
    "            \"logit\": logit,\n",
    "            \"clipwise_output\": clipwise_output\n",
    "        }\n",
    "\n",
    "        return output_dict\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=0.01, momentum=0.9)\n",
    "#         scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "#         lr_scheduler = {\"scheduler\": scheduler }\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        y_pred = self.forward(x)\n",
    "#         print(y_pred['clipwise_output'].shape, y.shape)\n",
    "        loss = self.criterion(y_pred['clipwise_output'], y)\n",
    "        self.log('train_loss', loss,  on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        y_pred = self.forward(x)\n",
    "#         print(y_pred)\n",
    "        loss_max = self.criterion(torch.max(y_pred['framewise_output'], 1)[0], y)\n",
    "        loss_clip = self.criterion(y_pred['clipwise_output'], y)\n",
    "        loss = loss_clip + 0.5*loss_max\n",
    "        y_pred_act = torch.sigmoid(y_pred['clipwise_output'])\n",
    "        lwlap_step, weight_step = lwlap_wrapper(y, y_pred_act)\n",
    "        lwlap_step = (lwlap_step * weight_step).sum()\n",
    "#         print('valid_epoch_loss = ', loss)\n",
    "#         print('valid_epoch_loss = ', lwlap_step)\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('lwlap_score', lwlap_step, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss, lwlap_step\n",
    "\n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        validation_step_outputs = np.array(validation_step_outputs)\n",
    "        validation_step_losses = validation_step_outputs[:, 0]\n",
    "        mean_loss = torch.stack([x for x in validation_step_losses]).mean()\n",
    "        \n",
    "        validation_step_scores = validation_step_outputs[:, 1]\n",
    "        mean_score = torch.stack([x for x in validation_step_scores]).mean()\n",
    "\n",
    "        print('valid_epoch_loss = ', mean_loss)\n",
    "        print('valid_epoch_lwlap = ', mean_score)\n",
    "        self.log('valid_epoch_loss', mean_loss, prog_bar=True, logger=True)\n",
    "        self.log('valid_epoch_lwlap', mean_score, prog_bar=True, logger=True)\n",
    "#         tqdm.write('Dice: \\t%.3f' % mean_loss)\n",
    "        return mean_loss, mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id_head_list = []\n",
    "for l_ in train_gby['species_id']:\n",
    "    species_id_head_list.append(l_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/user/.cache/torch/hub/zhanghang1989_ResNeSt_master\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | encoder   | Sequential | 25.4 M\n",
      "1 | fc1       | Linear     | 4.2 M \n",
      "2 | att_block | AttBlock   | 98.4 K\n",
      "3 | criterion | BCELoss    | 0     \n",
      "-----------------------------------------\n",
      "29.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "29.7 M    Total params\n",
      "/home/user/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b0e0fec5ba4531995b91976b6bc00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(2.3934, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.0670)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The validation_epoch_end should not return anything as of 9.1. To log, use self.log(...) or self.write(...) directly in the LightningModule\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/user/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc9f9aa90b24d5785ae964ba0a1062f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96eec3feb23a4cbcb3773ae7b0478d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2939, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.2017)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a58562053e14810a97db2be513d20dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2827, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.2415)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6818c1ee5e024769938992c28e65d699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2682, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.3271)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90de8dae730246c2aae6b5694eea8176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2637, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.3412)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da99e1845e64ea8bcc38644628a8327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2489, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.3892)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021b5d04a39849a3ae018e0fe5ad763c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2469, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.4048)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98a7ef525dd4cbfb632c65290917822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2315, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.4796)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f457c8bde85d404d86bac4b2a67e1070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2343, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.5107)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963a3fdb6951438d892580f79721e277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2366, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.5040)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83714e92cddc425398fdd4b3b74516cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2210, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.5219)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72256a022b794e54971f749515b45f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2221, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.5453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6e995d8d6a40be8077bdc00e996389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2166, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.5552)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc7c0c275c843a18bc3d93f34d18b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2117, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.5926)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2606dc0dcb0d4e249ba93fdff0e9b85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2094, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.5893)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebe3b33a2b64d2aa0db745f9a75f977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2015, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.6232)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fb3eb53bc44a51ae810774386f7595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1987, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.6505)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10005680c7ad46f9aeafed6b906b49fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1951, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.6661)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc82f0be566f4a25b0e5838754e99413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1934, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.6754)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419fd2d080314883b98793686eea2f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1876, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.6857)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281e6eb1640e4142b2c4884b0ad41f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1758, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7130)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed08eb0f4ff446e87f80eba00898ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1691, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7357)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515847a3292540b4803e0c7b40c65e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1692, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7558)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4aa76c2da540c09ff451ef1e079929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1650, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7678)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da71d24a32b436eb72ea6f993dce852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1663, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7476)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046b3f432698442b9584c178b9be6707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1603, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7779)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2163027287437eb23c8eed148d5ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1556, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7957)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9ab13a8736478e87a6e7e2db2600ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1598, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7847)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eef3f8f0572479f99bfb4497db828c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1595, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8048)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d653c94009e446d397961cb71f704c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1553, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8084)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3339277b7c794fa99f5a5be5a5b55f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1576, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8048)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d491cd470499446f9e937372d7f2f0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1567, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8212)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40855eff4d43489cbfe21b6d41a1cddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1559, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8199)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be192723e4de4ab486bb487c99ad3d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1488, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8215)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ab80138e044291a0bbdc22d3d2c811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1582, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8403)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1df747b9d24425bfd88a9d19db32e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1549, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8426)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49052348e0b45c680a5681bf6061554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1599, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8316)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d86cfccc4b74d06901a5bb07b0bbb5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1669, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8428)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8182b9d2519243ac9a85288b9a248b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1703, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8460)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c19b0aa5f84055bb089b557893dfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1618, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8462)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2679e51cca46a2acbba109f1cdd5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1746, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8590)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f83ce11b624750aff049bc2aa4d764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1807, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8403)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f7e440f1fd422e990b217e2788402f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1696, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8602)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f67e3b8c9a0460289e16ac99e22a782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1837, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8469)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c28516df3b543f5bfaecc507c0a3069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1961, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8367)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df124d65fdd14f50ae57f0a4bda7e30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.1892, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8364)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afdb296c00845ba8b5abf96fe2c9258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2054, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8366)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513a591d8e41497385c4c6c81d58a317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2025, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8527)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619eae063dee446bb5f613dc8d439c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2245, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8245)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d809ac4646fe484eb7d00837d46e1ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2029, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8493)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13a342df37249188e4a466448fa02bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2214, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8375)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8736f590a8498ab37118da9556dd9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2205, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8461)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26961cb604a34d8c976100d634ba81b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2597, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7883)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbff79cee0bc463db6dd255fb8626402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2510, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8485)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd28b6fe1a244bca8796b395a9118967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2561, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8193)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f088ecbebbbf4bb4863e534fd1bbc08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2465, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8605)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7cfa08b08b480baba01ea0397bb18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2520, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8107)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe89b33878b437c9fb700ad0e0ba46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2572, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8300)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da344b07b0624231a0a635de18640678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.3175, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8097)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcca602226e43949a19cc5c3241a191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2577, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8666)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7cbc7f6f3548ebbb897d6b6f177766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2682, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7734)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4f3a23a72c45938b008ffa894a9f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2813, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8439)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67cb0b061b54d0785f74a2e48d081cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2712, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8354)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bd3645135e40c1b6b14489a4455cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2849, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8544)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f3597328be4806b2826b8922c7b589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2970, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7818)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2cd3ca51d04541a354334429f7c274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2599, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8621)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d61a25ff9f4b9483d9695647bb5e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.3012, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8079)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e197fe1bc94e51a35832aa09d5be82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2894, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8547)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c5332823bd480fa7fd79d396f89c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.3276, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7974)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a2a641d10646948aeb5359942a591d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.3160, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8223)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7115053a2c14bf9827b2bc8a01f316d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.3180, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8281)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bfdf30ad3147fcb02584758ed6a736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.3060, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8026)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c4d080e69e407297e3ed08ace00be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.3474, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8013)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be04bc1693e40a8984de23e600b45a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.3384, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7996)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594e65e98a2f4515b28792133f7c40b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.3073, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8208)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582fdbe80fd44b5e9b9fee253ac6286f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.3771, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8278)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0282b5f37d814615b5cd9e4ffbee4105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.3210, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8286)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1364bef01e48918b4fdb58de87311f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.2928, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8247)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a69985217194c09b26c10a001001708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.3249, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8266)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5db6bb29044257afc9d6fb276bbaba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.3677, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7896)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627c949a29434df18bcb892d976ca86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.4061, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8092)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_gby, species_id_head_list)):\n",
    "    # Picking only first fold to train/val on\n",
    "    # This means loss of 20% training data\n",
    "    # To avoid this, you can train 5 different models on 5 folds and average predictions\n",
    "    train_data = train_df[~train_df['name'].isin(train_gby.iloc[val_index]['name'])]\n",
    "    valid_data = train_df[train_df['name'].isin(train_gby.iloc[val_index]['name'])]    \n",
    "    \n",
    "    train_data.reset_index(inplace=True, drop=True)\n",
    "    valid_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    train_dataset = SpectrogramTrainDataset(train_data, config[\"dataset\"][\"params\"])\n",
    "    valid_dataset = SpectrogramValidDataset(valid_data, config[\"dataset\"][\"params\"])\n",
    "    \n",
    "    train_loader = data.DataLoader(train_dataset, **config[\"loader\"][\"train\"])\n",
    "    valid_loader = data.DataLoader(valid_dataset, **config[\"loader\"][\"valid\"])\n",
    "        \n",
    "    model = LitModule()\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=EPOCH,\n",
    "        default_root_dir=OUTPUT_DIR,\n",
    "        gpus=1,\n",
    "#         callbacks=[early_stop_callback],\n",
    "        deterministic=True,\n",
    "        benchmark=True\n",
    "    )\n",
    "    trainer.fit(model, train_loader, valid_loader)\n",
    "    \n",
    "    break\n",
    "    \n",
    "    torch.save(model.state_dict(), OUTPUT_DIR + 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), OUTPUT_DIR + 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
