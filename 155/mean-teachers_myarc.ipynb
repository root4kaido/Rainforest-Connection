{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012249,
     "end_time": "2021-02-04T10:21:04.071237",
     "exception": false,
     "start_time": "2021-02-04T10:21:04.058988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "I wanted to share something that worked pretty well for me early on in this competition. The idea comes from a [2018 paper](https://arxiv.org/pdf/1703.01780.pdf) titled *Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results* by Antti Tarvainen and Harri Valpola. \n",
    "\n",
    "### Mean Teacher\n",
    "Biefly, the idea is to use two models. A student model with weights trained the standard way, using backprop. And a teacher model with weights that are an exponential moving average of the student's weights. The teacher is the *mean* of the student \\*ba dum tss\\*. The student is then trained using two different losses, a standard classification loss and a consistency loss that penalizes student predictions that deviate from the teaher's. \n",
    "\n",
    "![](https://raw.githubusercontent.com/CuriousAI/mean-teacher/master/mean_teacher.png)\n",
    "\n",
    "Mean teachers are useful in a semi-supervised context where we have both labeled and unlabeled samples. The consistency loss on the unlabeled samples acts as a form of regularization and helps the model generalize better. As an added bonus the final teacher model is a temporal ensemble which tends to perform better than the results at the end of a single epoch. \n",
    "\n",
    "### Missing Labels\n",
    "As a few others have pointed out, there are a lot of missing labels. If we were to randomly sample a segment from the training data, we might consider it completely unlabeled rather than rely on the provided labels. We'll train our mean teacher model(s) on two classes of data, carefully selected positive samples and randomly selected unlabeled samples. The classification loss won't apply to the unlabeled samples. \n",
    "\n",
    "![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F4704212%2F9ca088bb386abf7114543c019c1d8a5f%2Ffig.png?generation=1609892974092435&alt=media)\n",
    "\n",
    "*Thanks to [shinmura0](https://www.kaggle.com/shinmurashinmura) for the great visualization!*\n",
    "\n",
    "### Results\n",
    "For me, mean teacher worked a good bit better than baseline models with similar configurations. \n",
    "\n",
    "|                                         | Baseline | Mean Teacher |\n",
    "|-----------------------------------------|----------|--------------|\n",
    "| Well Tuned, 5 fold, from my local setup | 0.847        | **0.865**            |\n",
    "| Single fold Expt1 on Kaggle                   | 0.592**        | **0.786**            |\n",
    "| Single fold Expt2 on Kaggle                   | 0.826        | **0.830**            |\n",
    "| 5 Fold on Kaggle                        | ?        | ?            |\n",
    "\n",
    "\\*\\* I might have accidentally sabatoged this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-04T10:21:04.099073Z",
     "iopub.status.busy": "2021-02-04T10:21:04.098511Z",
     "iopub.status.idle": "2021-02-04T10:21:33.566885Z",
     "shell.execute_reply": "2021-02-04T10:21:33.565535Z"
    },
    "papermill": {
     "duration": 29.485143,
     "end_time": "2021-02-04T10:21:33.567104",
     "exception": false,
     "start_time": "2021-02-04T10:21:04.081961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip -q install --upgrade pip\n",
    "# !pip -q install timm\n",
    "# !pip -q install torchlibrosa\n",
    "# !pip -q install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting cPython\n",
      "  Downloading cPython-0.0.6.tar.gz (4.7 kB)\n",
      "Collecting pymongo\n",
      "  Downloading pymongo-3.11.3-cp36-cp36m-manylinux2014_x86_64.whl (509 kB)\n",
      "\u001b[K     |████████████████████████████████| 509 kB 2.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from cPython) (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cPython) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cPython) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cPython) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cPython) (1.25.10)\n",
      "Building wheels for collected packages: cPython\n",
      "  Building wheel for cPython (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cPython: filename=cPython-0.0.6-py3-none-any.whl size=4913 sha256=959eaee8e79a6da4eaa53d305960491cde3363e24bd3fe682e9fd4e6644b8994\n",
      "  Stored in directory: /home/user/.cache/pip/wheels/b2/0f/fa/faf1ddc5dbe2fbd858f0d53fa7cc7b5f060d9986a3e1f18810\n",
      "Successfully built cPython\n",
      "Installing collected packages: pymongo, cPython\n",
      "Successfully installed cPython-0.0.6 pymongo-3.11.3\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install cPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-04T10:21:33.599361Z",
     "iopub.status.busy": "2021-02-04T10:21:33.594854Z",
     "iopub.status.idle": "2021-02-04T10:21:37.692586Z",
     "shell.execute_reply": "2021-02-04T10:21:37.692102Z"
    },
    "papermill": {
     "duration": 4.114134,
     "end_time": "2021-02-04T10:21:37.692748",
     "exception": false,
     "start_time": "2021-02-04T10:21:33.578614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import audiomentations as A\n",
    "import os, time, librosa, random\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from timm.models import resnet34d\n",
    "from timm.models.efficientnet import tf_efficientnet_b0_ns\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "# from contextlib import nullcontext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010589,
     "end_time": "2021-02-04T10:21:37.714892",
     "exception": false,
     "start_time": "2021-02-04T10:21:37.704303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config\n",
    "We'll start by setting up some global config variable that we'll access later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_ROOT = Path(\"/home/knikaido/work/Rainforest-Connection/data\")\n",
    "RAW_DATA = INPUT_ROOT / \"rfcx-species-audio-detection\"\n",
    "TRAIN_AUDIO_DIR = RAW_DATA / \"train\"\n",
    "# TRAIN_RESAMPLED_AUDIO_DIRS = [\n",
    "#   INPUT_ROOT / \"birdsong-resampled-train-audio-{:0>2}\".format(i)  for i in range(5)\n",
    "# ]\n",
    "TEST_AUDIO_DIR = RAW_DATA / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-04T10:21:37.744508Z",
     "iopub.status.busy": "2021-02-04T10:21:37.743994Z",
     "iopub.status.idle": "2021-02-04T10:21:37.747570Z",
     "shell.execute_reply": "2021-02-04T10:21:37.747078Z"
    },
    "papermill": {
     "duration": 0.021958,
     "end_time": "2021-02-04T10:21:37.747706",
     "exception": false,
     "start_time": "2021-02-04T10:21:37.725748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global Vars\n",
    "NO_LABEL = -1\n",
    "NUM_CLASSES = 24\n",
    "\n",
    "\n",
    "class config:\n",
    "    seed = 42\n",
    "    device = \"cuda:0\"\n",
    "    \n",
    "    train_tp_csv = RAW_DATA / 'train_tp.csv'\n",
    "    test_csv = RAW_DATA / 'sample_submission.csv'\n",
    "    save_path = './output/'\n",
    "    \n",
    "    encoder = resnet34d\n",
    "    encoder_features = 1024\n",
    "    \n",
    "    percent_unlabeled = 1.0\n",
    "    consistency_weight = 100.0\n",
    "    consistency_rampup = 1000 # 6 epochs\n",
    "    ema_decay = 0.995\n",
    "    positive_weight = 2.0\n",
    "    \n",
    "    lr = 1e-3\n",
    "    epochs = 25\n",
    "    train_batch_size = 6\n",
    "    valid_batch_size = 2\n",
    "    num_workers = 1\n",
    "    train_5_folds = True\n",
    "    \n",
    "    period = 6 # 6 second clips\n",
    "    step = 1\n",
    "    model_params = {\n",
    "        'sample_rate': 48000,\n",
    "        'window_size': 2048,\n",
    "        'hop_size': 512,\n",
    "        'mel_bins': 384,\n",
    "        'fmin': 20,\n",
    "        'fmax': 48000 // 2,\n",
    "        'classes_num': NUM_CLASSES\n",
    "    }\n",
    "    \n",
    "    augmenter = A.Compose([\n",
    "#         A.AddGaussianNoise(p=0.33, max_amplitude=0.02),\n",
    "#         A.AddGaussianSNR(p=0.33),\n",
    "#         A.FrequencyMask(min_frequency_band=0.01,  max_frequency_band=0.25, p=0.33),\n",
    "#         A.TimeMask(min_band_part=0.01, max_band_part=0.25, p=0.33),\n",
    "#         A.Gain(p=0.33)\n",
    "        \n",
    "        A.AddGaussianNoise(p=0.2, max_amplitude=0.02),\n",
    "        A.AddGaussianSNR(p=0.2),\n",
    "        A.Gain(min_gain_in_db=-15,max_gain_in_db=15,p=0.3),\n",
    "        A.PitchShift(min_semitones=-1, max_semitones=1, p=0.2)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-04T10:21:37.777743Z",
     "iopub.status.busy": "2021-02-04T10:21:37.772258Z",
     "iopub.status.idle": "2021-02-04T10:21:37.805623Z",
     "shell.execute_reply": "2021-02-04T10:21:37.806074Z"
    },
    "papermill": {
     "duration": 0.047669,
     "end_time": "2021-02-04T10:21:37.806237",
     "exception": false,
     "start_time": "2021-02-04T10:21:37.758568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Utils - Not much interesting going on here.\n",
    "\n",
    "def get_n_fold_df(csv_path, folds=5):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df_group = df.groupby(\"recording_id\")[[\"species_id\"]].first().reset_index()\n",
    "    df_group = df_group.sample(frac=1, random_state=config.seed).reset_index(drop=True)\n",
    "    df_group.loc[:, 'fold'] = -1\n",
    "\n",
    "    X = df_group[\"recording_id\"].values\n",
    "    y = df_group[\"species_id\"].values\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=folds, random_state=config.seed)\n",
    "    for fold, (t_idx, v_idx) in enumerate(kfold.split(X, y)):\n",
    "        df_group.loc[v_idx, \"fold\"] = fold\n",
    "\n",
    "    return df.merge(df_group[['recording_id', 'fold']], on=\"recording_id\", how=\"left\")\n",
    "\n",
    "\n",
    "def get_n_fold_df(csv_path, folds=5):\n",
    "    train_df = pd.read_pickle(RAW_DATA / \"train_gby_wav_raw_denoise.pkl\")\n",
    "    train_gby = pd.read_pickle(RAW_DATA / \"train_gby_denoise.pkl\")\n",
    "    species_id_head_list = []\n",
    "    for l_ in train_gby['species_id']:\n",
    "        species_id_head_list.append(l_[0])\n",
    "\n",
    "\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    df_group = df.groupby(\"recording_id\")[[\"species_id\"]].first().reset_index()\n",
    "    df_group = df_group.sample(frac=1, random_state=config.seed).reset_index(drop=True)\n",
    "    df_group.loc[:, 'fold'] = -1\n",
    "\n",
    "    X = df_group[\"recording_id\"].values\n",
    "    y = df_group[\"species_id\"].values\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=folds, random_state=config.seed)\n",
    "    for fold, (t_idx, v_idx) in enumerate(kfold.split(X, y)):\n",
    "        df_group.loc[v_idx, \"fold\"] = fold\n",
    "\n",
    "    return df.merge(df_group[['recording_id', 'fold']], on=\"recording_id\", how=\"left\")\n",
    "    \n",
    "\n",
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def sigmoid_rampup(current, rampup_length):\n",
    "    \"\"\"Exponential rampup from https://arxiv.org/abs/1610.02242\"\"\"\n",
    "    if rampup_length == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        current = np.clip(current, 0.0, rampup_length)\n",
    "        phase = 1.0 - current / rampup_length\n",
    "        return float(np.exp(-5.0 * phase * phase))\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class MetricMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.y_true = []\n",
    "        self.y_pred = []\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        try:\n",
    "            self.y_true.extend(y_true.detach().cpu().numpy().tolist())\n",
    "            self.y_pred.extend(torch.sigmoid(y_pred).cpu().detach().numpy().tolist())\n",
    "        except:\n",
    "            print(\"UPDATE FAILURE\")\n",
    "\n",
    "    def update_list(self, y_true, y_pred):\n",
    "        self.y_true.extend(y_true)\n",
    "        self.y_pred.extend(y_pred)\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        score_class, weight = lwlrap(np.array(self.y_true), np.array(self.y_pred))\n",
    "        self.score = (score_class * weight).sum()\n",
    "\n",
    "        return self.score\n",
    "    \n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "\n",
    "def lwlrap(truth, scores):\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = _one_sample_positive_class_precisions(scores[sample_num, :],\n",
    "                                                                                     truth[sample_num, :])\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = precision_at_hits\n",
    "\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    return per_class_lwlrap, weight_per_class\n",
    "\n",
    "\n",
    "def pretty_print_metrics(fold, epoch, optimizer, train_loss_metrics, val_loss_metrics):\n",
    "    print(f\"\"\"\n",
    "    {time.ctime()} \\n\n",
    "    Fold:{fold}, Epoch:{epoch}, LR:{optimizer.param_groups[0]['lr']:.7}, Cons. Weight: {train_loss_metrics['consistency_weight']}\\n\n",
    "    --------------------------------------------------------\n",
    "    Metric:              Train    |   Val\n",
    "    --------------------------------------------------------\n",
    "    Loss:                {train_loss_metrics['loss']:0.4f}   |   {val_loss_metrics['loss']:0.4f}\\n\n",
    "    LWLRAP:              {train_loss_metrics['lwlrap']:0.4f}   |   {val_loss_metrics['lwlrap']:0.4f}\\n\n",
    "    Class Loss:          {train_loss_metrics['class_loss']:0.4f}   |   {val_loss_metrics['class_loss']:0.4f}\\n\n",
    "    Consistency Loss:    {train_loss_metrics['consistency_loss']:0.4f}   |   {val_loss_metrics['consistency_loss']:0.4f}\\n\n",
    "    --------------------------------------------------------\\n\n",
    "    \"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, data_path, period=10, step=1):\n",
    "        self.data_path = data_path\n",
    "        self.period = period\n",
    "        self.step = step\n",
    "        self.recording_ids = list(df[\"recording_id\"].unique())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.recording_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        recording_id = self.recording_ids[idx]\n",
    "\n",
    "        y, sr = sf.read(f\"{self.data_path}/{recording_id}.flac\")\n",
    "\n",
    "        len_y = len(y)\n",
    "        effective_length = sr * self.period\n",
    "        effective_step = sr * self.step\n",
    "\n",
    "        y_ = []\n",
    "        i = 0\n",
    "        while i+effective_length <= len_y:\n",
    "            y__ = y[i:i + effective_length]\n",
    "\n",
    "            y_.append(y__)\n",
    "            i = i + effective_step\n",
    "\n",
    "        y = np.stack(y_)\n",
    "\n",
    "        label = np.zeros(NUM_CLASSES, dtype='f')\n",
    "\n",
    "        return {\n",
    "            \"waveform\": y,\n",
    "            \"target\": torch.tensor(label, dtype=torch.float),\n",
    "            \"id\": recording_id\n",
    "        }\n",
    "\n",
    "\n",
    "def predict_on_test(model, test_loader):\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    id_list = []\n",
    "    with torch.no_grad():\n",
    "        t = tqdm(test_loader)\n",
    "        for i, sample in enumerate(t):\n",
    "            input = sample[\"waveform\"].to(config.device)\n",
    "            bs, seq, w = input.shape\n",
    "            input = input.reshape(bs * seq, w)\n",
    "            id = sample[\"id\"]\n",
    "            output, _ = model(input)\n",
    "            output = output.reshape(bs, seq, -1)\n",
    "            output, _ = torch.max(output, dim=1)\n",
    "            \n",
    "            output = output.cpu().detach().numpy().tolist()\n",
    "            pred_list.extend(output)\n",
    "            id_list.extend(id)\n",
    "\n",
    "    return pred_list, id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01127,
     "end_time": "2021-02-04T10:21:37.828671",
     "exception": false,
     "start_time": "2021-02-04T10:21:37.817401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model\n",
    "The model should look pretty familiar if you're using [SED](https://arxiv.org/abs/1912.04761). (Huge thanks to [Hidehisa Arai](https://www.kaggle.com/hidehisaarai1213) and their [SED Notebook](https://www.kaggle.com/hidehisaarai1213/introduction-to-sound-event-detection)!) You could use any model you'd like here. There's just one small tweak we need to make for our mean teacher setup. We need to \"detach\" the teacher's parameters so they aren't updated by the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_params = {\n",
    "    \"tf_efficientnet_b0_ns\": {\n",
    "        \"features\": 1280,\n",
    "        \"init_op\": partial(tf_efficientnet_b0_ns, pretrained=True, drop_path_rate=0.2)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T10:21:37.854389Z",
     "iopub.status.busy": "2021-02-04T10:21:37.853551Z",
     "iopub.status.idle": "2021-02-04T10:21:37.871645Z",
     "shell.execute_reply": "2021-02-04T10:21:37.871227Z"
    },
    "papermill": {
     "duration": 0.031971,
     "end_time": "2021-02-04T10:21:37.871772",
     "exception": false,
     "start_time": "2021-02-04T10:21:37.839801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        super().__init__()\n",
    "        self.conv_attention = nn.Conv1d(in_channels=in_features, \n",
    "                                        out_channels=out_features,\n",
    "                                        kernel_size=1, stride=1, \n",
    "                                        padding=0, bias=True)\n",
    "        self.conv_classes = nn.Conv1d(in_channels=in_features, \n",
    "                                      out_channels=out_features,\n",
    "                                      kernel_size=1, stride=1, \n",
    "                                      padding=0, bias=True)\n",
    "        self.batch_norm_attention = nn.BatchNorm1d(out_features)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.conv_attention)\n",
    "        init_layer(self.conv_classes)\n",
    "        init_bn(self.batch_norm_attention)\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm_att = torch.softmax(torch.tanh(self.conv_attention(x)), dim=-1)\n",
    "        classes = self.conv_classes(x)\n",
    "        x = torch.sum(norm_att * classes, dim=2)\n",
    "        return x, norm_att, classes\n",
    "\n",
    "\n",
    "class SEDAudioClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, sample_rate, window_size, hop_size, \n",
    "                 mel_bins, fmin, fmax, classes_num):\n",
    "        super().__init__()\n",
    "        self.interpolate_ratio = 32\n",
    "\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, \n",
    "                                                 hop_length=hop_size,\n",
    "                                                 win_length=window_size, \n",
    "                                                 window='hann', center=True,\n",
    "                                                 pad_mode='reflect', \n",
    "                                                 freeze_parameters=True)\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size,\n",
    "                                                 n_mels=mel_bins, fmin=fmin, \n",
    "                                                 fmax=fmax, ref=1.0, \n",
    "                                                 amin=1e-10, top_db=None, \n",
    "                                                 freeze_parameters=True)\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm2d(mel_bins)\n",
    "#         self.encoder = partial(config.encoder, pretrained=True, in_chans=1)()\n",
    "        self.encoder = encoder_params['tf_efficientnet_b0_ns'][\"init_op\"]()\n",
    "        self.fc = nn.Linear(encoder_params['tf_efficientnet_b0_ns'][\"features\"], \n",
    "                            config.encoder_features, bias=True)\n",
    "        self.att_head = AttentionHead(config.encoder_features, classes_num)\n",
    "        self.avg_pool = nn.modules.pooling.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.batch_norm)\n",
    "        init_layer(self.fc)\n",
    "        self.att_head.init_weights()\n",
    "\n",
    "    def forward(self, input, spec_aug=False, \n",
    "                mixup_lambda=None, return_encoding=False):\n",
    "        x = self.spectrogram_extractor(input.float())\n",
    "        x = self.logmel_extractor(x)\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.batch_norm(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        x = x.expand(x.shape[0], 3, x.shape[2], x.shape[3])\n",
    "\n",
    "        x = self.encoder.forward_features(x)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_head(x)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        framewise_output = interpolate(segmentwise_output, self.interpolate_ratio)\n",
    "        return clipwise_output, framewise_output\n",
    "\n",
    "\n",
    "def get_model(is_mean_teacher=False):\n",
    "    model = SEDAudioClassifier(**config.model_params)\n",
    "    model = model.to(config.device)\n",
    "    \n",
    "    # Detach params for Exponential Moving Average Model (aka the Mean Teacher).\n",
    "    # We'll manually update these params instead of using backprop.\n",
    "    if is_mean_teacher:\n",
    "        for param in model.parameters():\n",
    "            param.detach_()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010754,
     "end_time": "2021-02-04T10:21:37.893954",
     "exception": false,
     "start_time": "2021-02-04T10:21:37.883200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss Function\n",
    "The loss function has 2 components:\n",
    "\n",
    "1. A classification loss that only applies to labeled samples.\n",
    "2. A consistency loss that applies to all samples. \n",
    "\n",
    "For the consistency loss we'll use the mean square error between the student and teacher predictions. We'll slowly ramp up the influence of the consistency loss since we don't want bad, early predictions having too much influence. \n",
    "\n",
    "Notice that we're weighting the positive samples for the classification loss. This is because we know the positives are correct while we're less sure about the negatives due to the missing labels issue. I found that this works better in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T10:21:37.926428Z",
     "iopub.status.busy": "2021-02-04T10:21:37.925771Z",
     "iopub.status.idle": "2021-02-04T10:21:37.928560Z",
     "shell.execute_reply": "2021-02-04T10:21:37.928071Z"
    },
    "papermill": {
     "duration": 0.023537,
     "end_time": "2021-02-04T10:21:37.928679",
     "exception": false,
     "start_time": "2021-02-04T10:21:37.905142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid_mse_loss(input_logits, target_logits):\n",
    "    assert input_logits.size() == target_logits.size()\n",
    "    input_softmax = torch.sigmoid(input_logits)\n",
    "    target_softmax = torch.sigmoid(target_logits)\n",
    "    num_classes = input_logits.size()[1]\n",
    "    return F.mse_loss(input_softmax, target_softmax, size_average=False\n",
    "                     ) / num_classes\n",
    "\n",
    "\n",
    "class MeanTeacherLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.positive_weight = torch.ones(\n",
    "            NUM_CLASSES).to(config.device) * config.positive_weight\n",
    "        self.class_criterion = nn.BCEWithLogitsLoss(\n",
    "            reduction='none', pos_weight=self.positive_weight)\n",
    "        self.consistency_criterion = sigmoid_mse_loss\n",
    "\n",
    "    def make_safe(self, pred):\n",
    "        pred = torch.where(torch.isnan(pred), torch.zeros_like(pred), pred)\n",
    "        return torch.where(torch.isinf(pred), torch.zeros_like(pred), pred)\n",
    "        \n",
    "    def get_consistency_weight(self, epoch):\n",
    "        # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
    "        return config.consistency_weight * sigmoid_rampup(\n",
    "            epoch, config.consistency_rampup)\n",
    "    \n",
    "    def forward(self, student_pred, teacher_pred, target, classif_weights, epoch):\n",
    "        student_pred = self.make_safe(student_pred)\n",
    "        teacher_pred = self.make_safe(teacher_pred).detach().data\n",
    "\n",
    "        batch_size = len(target)\n",
    "        labeled_batch_size = target.ne(NO_LABEL).all(axis=1).sum().item() + 1e-3\n",
    "\n",
    "        student_classif, student_consistency = student_pred, student_pred\n",
    "        student_class_loss = (self.class_criterion(\n",
    "            student_classif, target) * classif_weights / labeled_batch_size).sum()\n",
    "\n",
    "        consistency_weights = self.get_consistency_weight(epoch)\n",
    "        consistency_loss = consistency_weights * self.consistency_criterion(\n",
    "            student_consistency, teacher_pred) / batch_size\n",
    "        loss = student_class_loss + consistency_loss\n",
    "        return loss, student_class_loss, consistency_loss, consistency_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01149,
     "end_time": "2021-02-04T10:21:37.952452",
     "exception": false,
     "start_time": "2021-02-04T10:21:37.940962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loader\n",
    "The data loader produces two types of samples:\n",
    "\n",
    "1. Labeled samples with the audio centered in the clip.\n",
    "2. Random unlabeled clips without labels selected from files with at least one true positive label.\n",
    "\n",
    "Each sample contains 2 different inputs, one for the student and one for the teacher. Different augmentations are applied to each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T10:21:37.997280Z",
     "iopub.status.busy": "2021-02-04T10:21:37.988160Z",
     "iopub.status.idle": "2021-02-04T10:21:38.000075Z",
     "shell.execute_reply": "2021-02-04T10:21:37.999624Z"
    },
    "papermill": {
     "duration": 0.035765,
     "end_time": "2021-02-04T10:21:38.000182",
     "exception": false,
     "start_time": "2021-02-04T10:21:37.964417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanTeacherDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transforms, period=5, \n",
    "                 data_path=str(TRAIN_AUDIO_DIR), \n",
    "                 val=False, percent_unlabeled=0.0):\n",
    "        self.period = period\n",
    "        self.transforms = transforms\n",
    "        self.data_path = data_path\n",
    "        self.val = val\n",
    "        self.percent_unlabeled = percent_unlabeled\n",
    "\n",
    "        dfgby = df.groupby(\"recording_id\").agg(lambda x: list(x)).reset_index()\n",
    "        self.recording_ids = dfgby[\"recording_id\"].values\n",
    "        self.species_ids = dfgby[\"species_id\"].values\n",
    "        self.t_mins = dfgby[\"t_min\"].values\n",
    "        self.t_maxs = dfgby[\"t_max\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.recording_ids) * (1 + self.percent_unlabeled))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.recording_ids):\n",
    "            audio, label, rec_id, sr = self.get_unlabeled_item(idx)\n",
    "            # For unlabeled samples, we zero out the classification loss.\n",
    "            classif_weights = np.zeros(NUM_CLASSES, dtype='f')\n",
    "        else:\n",
    "            audio, label, rec_id, sr = self.get_labeled_item(idx)\n",
    "            classif_weights = np.ones(NUM_CLASSES, dtype='f')\n",
    "\n",
    "        audio_teacher = np.copy(audio)\n",
    "\n",
    "        # The 2 samples fed to the 2 models have should have different augmentations.\n",
    "        audio = self.transforms(samples=audio, sample_rate=sr)\n",
    "        audio_teacher = self.transforms(samples=audio_teacher, sample_rate=sr)\n",
    "        # assert (audio != audio_teacher).any()\n",
    "        \n",
    "        return {\n",
    "            \"waveform\": audio,\n",
    "            \"teacher_waveform\": audio_teacher,\n",
    "            \"target\": torch.tensor(label, dtype=torch.float),\n",
    "            \"classification_weights\": classif_weights,\n",
    "            \"id\": rec_id\n",
    "        }\n",
    "\n",
    "    def get_labeled_item(self, idx):\n",
    "        recording_id = self.recording_ids[idx]\n",
    "        species_id = self.species_ids[idx]\n",
    "        t_min, t_max = self.t_mins[idx], self.t_maxs[idx]\n",
    "\n",
    "        rec, sr = sf.read(f\"{self.data_path}/{recording_id}.flac\")\n",
    "\n",
    "        len_rec = len(rec)\n",
    "        effective_length = sr * self.period\n",
    "        rint = np.random.randint(len(t_min))\n",
    "        tmin, tmax = round(sr * t_min[rint]), round(sr * t_max[rint])\n",
    "        dur = tmax - tmin\n",
    "        min_dur = min(dur, round(sr * self.period))\n",
    "        \n",
    "#         start_min = max(0, tmax-effective_length)\n",
    "#         start_max = min(tmin, len_rec - effective_length)\n",
    "#         start = np.random.randint(start_min, start_max)\n",
    "#         rec = rec[start:start + effective_length]\n",
    "\n",
    "        center = round((tmin + tmax) / 2)\n",
    "        rand_start = center - effective_length + max(min_dur - dur//2, 0)\n",
    "        if rand_start < 0:\n",
    "            rand_start = 0\n",
    "        rand_end = center - max(min_dur - dur//2, 0)\n",
    "        start = np.random.randint(rand_start, rand_end)\n",
    "        rec = rec[start:start + effective_length]\n",
    "        if len(rec) < effective_length:\n",
    "            new_rec = np.zeros(effective_length, dtype=rec.dtype)\n",
    "            start1 = np.random.randint(effective_length - len(rec))\n",
    "            new_rec[start1:start1 + len(rec)] = rec\n",
    "            rec = new_rec.astype(np.float32)\n",
    "        else:\n",
    "            rec = rec.astype(np.float32)\n",
    "\n",
    "        start_time = start / sr\n",
    "        end_time = (start + effective_length) / sr\n",
    "\n",
    "        label = np.zeros(NUM_CLASSES, dtype='f')\n",
    "\n",
    "        for i in range(len(t_min)):\n",
    "            if (t_min[i] >= start_time) & (t_max[i] <= end_time):\n",
    "                label[species_id[i]] = 1\n",
    "            elif start_time <= ((t_min[i] + t_max[i]) / 2) <= end_time:\n",
    "                label[species_id[i]] = 1\n",
    "\n",
    "        return rec, label, recording_id, sr\n",
    "\n",
    "    def get_unlabeled_item(self, idx, random_sample=False):\n",
    "        real_idx = idx - len(self.recording_ids)\n",
    "        # We want our validation set to be fixed.\n",
    "        if self.val:\n",
    "            rec_id = self.recording_ids[real_idx]\n",
    "        else:\n",
    "            rec_id = random.sample(list(self.recording_ids), 1)[0]\n",
    "\n",
    "        rec, sr = sf.read(f\"{self.data_path}/{rec_id}.flac\")\n",
    "        effective_length = int(sr * self.period)\n",
    "        max_end = len(rec) - effective_length\n",
    "        if self.val:\n",
    "            # Fixed start for validation. Probaably a better way to do this.\n",
    "            start = int(idx * 16963 % max_end)\n",
    "        else:\n",
    "            start = np.random.randint(0, max_end)\n",
    "        rec = rec[start:(start+effective_length)]\n",
    "        rec = rec.astype(np.float32)\n",
    "\n",
    "        label = np.ones(NUM_CLASSES, dtype='f') * NO_LABEL\n",
    "\n",
    "        return rec, label, rec_id, sr\n",
    "\n",
    "    \n",
    "def get_data_loader(df, b_size, is_val=False):\n",
    "    dataset = MeanTeacherDataset(\n",
    "        df=df,\n",
    "        transforms=config.augmenter,\n",
    "        period=config.period,\n",
    "        percent_unlabeled=config.percent_unlabeled\n",
    "    )\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=b_size,\n",
    "        shuffle=not is_val,\n",
    "        drop_last=not is_val,\n",
    "        num_workers=config.num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012484,
     "end_time": "2021-02-04T10:21:38.023697",
     "exception": false,
     "start_time": "2021-02-04T10:21:38.011213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training\n",
    "At the end of each training step we update the teacher weights by averaging in the latest student weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T10:21:38.061363Z",
     "iopub.status.busy": "2021-02-04T10:21:38.060718Z",
     "iopub.status.idle": "2021-02-04T10:21:38.063124Z",
     "shell.execute_reply": "2021-02-04T10:21:38.063500Z"
    },
    "papermill": {
     "duration": 0.027268,
     "end_time": "2021-02-04T10:21:38.063621",
     "exception": false,
     "start_time": "2021-02-04T10:21:38.036353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update teacher to be exponential moving average of student params.\n",
    "def update_teacher_params(student, teacher, alpha, global_step):\n",
    "    # Use the true average until the exponential average is more correct\n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    for ema_param, param in zip(teacher.parameters(), student.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n",
    "\n",
    "\n",
    "def train_one_epoch(student, mean_teacher, loader, \n",
    "                    criterion, optimizer, scheduler, epoch):\n",
    "    global_step = 0\n",
    "    losses = AverageMeter()\n",
    "    consistency_loss_avg = AverageMeter()\n",
    "    class_loss_avg = AverageMeter()\n",
    "    comp_metric = MetricMeter()\n",
    "    \n",
    "    student.train()\n",
    "    mean_teacher.train()\n",
    "#     context = nullcontext()\n",
    "    \n",
    "    t = tqdm(loader)\n",
    "    for i, sample in enumerate(t):\n",
    "        student_input = sample['waveform'].to(config.device)\n",
    "        teacher_input = sample['teacher_waveform'].to(config.device)\n",
    "        target = sample['target'].to(config.device)\n",
    "        classif_weights = sample['classification_weights'].to(config.device)\n",
    "        batch_size = len(target)\n",
    "\n",
    "        student_pred, _  = student(student_input)\n",
    "        teacher_pred, _  = mean_teacher(teacher_input)\n",
    "\n",
    "        loss, class_loss, consistency_loss, consistency_weight = criterion(\n",
    "            student_pred, teacher_pred, target, classif_weights, epoch)\n",
    "\n",
    "#         if not is_val:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        update_teacher_params(student, mean_teacher, \n",
    "                              config.ema_decay, global_step)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        comp_metric.update(target, student_pred)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        consistency_loss_avg.update(consistency_loss.item(), batch_size)\n",
    "        class_loss_avg.update(class_loss.item(), batch_size)\n",
    "        global_step += 1\n",
    "\n",
    "        t.set_description(f\"Epoch:{epoch} - Loss:{losses.avg:0.4f}\")\n",
    "    t.close()\n",
    "    return {'lwlrap':comp_metric.avg, \n",
    "            'loss':losses.avg, \n",
    "            'consistency_loss':consistency_loss_avg.avg, \n",
    "            'class_loss':class_loss_avg.avg, \n",
    "            'consistency_weight':consistency_weight}\n",
    "\n",
    "\n",
    "def valid_one_epoch(student, mean_teacher, loader, \n",
    "                    criterion, optimizer, scheduler, epoch):\n",
    "    global_step = 0\n",
    "    losses = AverageMeter()\n",
    "    consistency_loss_avg = AverageMeter()\n",
    "    class_loss_avg = AverageMeter()\n",
    "    comp_metric = MetricMeter()\n",
    "    \n",
    "    student.eval()\n",
    "    mean_teacher.eval()\n",
    "    context = torch.no_grad()\n",
    "#     else:\n",
    "#     student.train()\n",
    "#     mean_teacher.train()\n",
    "#     context = nullcontext()\n",
    "    \n",
    "    with context:\n",
    "        t = tqdm(loader)\n",
    "        for i, sample in enumerate(t):\n",
    "            student_input = sample['waveform'].to(config.device)\n",
    "            teacher_input = sample['teacher_waveform'].to(config.device)\n",
    "            target = sample['target'].to(config.device)\n",
    "            classif_weights = sample['classification_weights'].to(config.device)\n",
    "            batch_size = len(target)\n",
    "\n",
    "            student_pred, _  = student(student_input)\n",
    "            teacher_pred, _  = mean_teacher(teacher_input)\n",
    "\n",
    "            loss, class_loss, consistency_loss, consistency_weight = criterion(\n",
    "                student_pred, teacher_pred, target, classif_weights, epoch)\n",
    "\n",
    "            comp_metric.update(target, student_pred)\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            consistency_loss_avg.update(consistency_loss.item(), batch_size)\n",
    "            class_loss_avg.update(class_loss.item(), batch_size)\n",
    "            global_step += 1\n",
    "\n",
    "            t.set_description(f\"Epoch:{epoch} - Loss:{losses.avg:0.4f}\")\n",
    "        t.close()\n",
    "    return {'lwlrap':comp_metric.avg, \n",
    "            'loss':losses.avg, \n",
    "            'consistency_loss':consistency_loss_avg.avg, \n",
    "            'class_loss':class_loss_avg.avg, \n",
    "            'consistency_weight':consistency_weight}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011615,
     "end_time": "2021-02-04T10:21:38.087489",
     "exception": false,
     "start_time": "2021-02-04T10:21:38.075874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally putting everything together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-04T10:21:38.121206Z",
     "iopub.status.busy": "2021-02-04T10:21:38.120697Z",
     "iopub.status.idle": "2021-02-04T14:37:42.274750Z",
     "shell.execute_reply": "2021-02-04T14:37:42.269816Z"
    },
    "papermill": {
     "duration": 15364.175867,
     "end_time": "2021-02-04T14:37:42.274884",
     "exception": false,
     "start_time": "2021-02-04T10:21:38.099017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/librosa/filters.py:239: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  \"Empty filters detected in mel frequency basis. \"\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]/home/user/.local/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  \n",
      "Epoch:0 - Loss:7.1068: 100%|██████████| 299/299 [03:40<00:00,  1.35it/s]\n",
      "Epoch:0 - Loss:3.2084: 100%|██████████| 233/233 [00:57<00:00,  4.06it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:00:59 2021 \n",
      "\n",
      "    Fold:0, Epoch:0, LR:3.422702e-05, Cons. Weight: 0.6737946999085467\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                7.1068   |   3.2084\n",
      "\n",
      "    LWLRAP:              0.2405   |   0.3936\n",
      "\n",
      "    Class Loss:          7.1003   |   3.1982\n",
      "\n",
      "    Consistency Loss:    0.0065   |   0.0102\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from -inf --> 0.39363536120979636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 - Loss:5.7553: 100%|██████████| 299/299 [03:36<00:00,  1.38it/s]\n",
      "Epoch:1 - Loss:2.6877: 100%|██████████| 233/233 [00:54<00:00,  4.24it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:05:30 2021 \n",
      "\n",
      "    Fold:0, Epoch:1, LR:0.0001045366, Cons. Weight: 0.6805630463993154\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                5.7553   |   2.6877\n",
      "\n",
      "    LWLRAP:              0.4127   |   0.5835\n",
      "\n",
      "    Class Loss:          5.7485   |   2.6738\n",
      "\n",
      "    Consistency Loss:    0.0068   |   0.0139\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.39363536120979636 --> 0.5834583554305217\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2 - Loss:4.5630: 100%|██████████| 299/299 [03:30<00:00,  1.42it/s]\n",
      "Epoch:2 - Loss:2.4661: 100%|██████████| 233/233 [00:51<00:00,  4.52it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:09:52 2021 \n",
      "\n",
      "    Fold:0, Epoch:2, LR:0.0002140463, Cons. Weight: 0.6873925077619901\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                4.5630   |   2.4661\n",
      "\n",
      "    LWLRAP:              0.5749   |   0.6550\n",
      "\n",
      "    Class Loss:          4.5534   |   2.4493\n",
      "\n",
      "    Consistency Loss:    0.0095   |   0.0169\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.5834583554305217 --> 0.654996547085904\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3 - Loss:3.5057: 100%|██████████| 299/299 [03:27<00:00,  1.44it/s]\n",
      "Epoch:3 - Loss:1.7926: 100%|██████████| 233/233 [00:55<00:00,  4.19it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:14:16 2021 \n",
      "\n",
      "    Fold:0, Epoch:3, LR:0.0003520366, Cons. Weight: 0.6942835600114377\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.5057   |   1.7926\n",
      "\n",
      "    LWLRAP:              0.6953   |   0.7294\n",
      "\n",
      "    Class Loss:          3.4968   |   1.7801\n",
      "\n",
      "    Consistency Loss:    0.0089   |   0.0124\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.654996547085904 --> 0.7294232736611193\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4 - Loss:3.3626: 100%|██████████| 299/299 [03:43<00:00,  1.34it/s]\n",
      "Epoch:4 - Loss:1.8504: 100%|██████████| 233/233 [00:56<00:00,  4.15it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:18:56 2021 \n",
      "\n",
      "    Fold:0, Epoch:4, LR:0.000505, Cons. Weight: 0.7012366820799585\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.3626   |   1.8504\n",
      "\n",
      "    LWLRAP:              0.7233   |   0.7444\n",
      "\n",
      "    Class Loss:          3.3541   |   1.8398\n",
      "\n",
      "    Consistency Loss:    0.0085   |   0.0105\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.7294232736611193 --> 0.7443563021392035\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5 - Loss:2.8582: 100%|██████████| 299/299 [03:37<00:00,  1.37it/s]\n",
      "Epoch:5 - Loss:2.0235: 100%|██████████| 233/233 [00:54<00:00,  4.30it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:23:28 2021 \n",
      "\n",
      "    Fold:0, Epoch:5, LR:0.0006579634, Cons. Weight: 0.7082523558272816\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.8582   |   2.0235\n",
      "\n",
      "    LWLRAP:              0.7791   |   0.7602\n",
      "\n",
      "    Class Loss:          2.8504   |   2.0117\n",
      "\n",
      "    Consistency Loss:    0.0078   |   0.0118\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.7443563021392035 --> 0.760222890646159\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6 - Loss:2.7226: 100%|██████████| 299/299 [03:35<00:00,  1.39it/s]\n",
      "Epoch:6 - Loss:1.8136: 100%|██████████| 233/233 [00:58<00:00,  4.01it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:28:02 2021 \n",
      "\n",
      "    Fold:0, Epoch:6, LR:0.0007959537, Cons. Weight: 0.7153310660505106\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.7226   |   1.8136\n",
      "\n",
      "    LWLRAP:              0.8030   |   0.7793\n",
      "\n",
      "    Class Loss:          2.7144   |   1.8037\n",
      "\n",
      "    Consistency Loss:    0.0081   |   0.0100\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.760222890646159 --> 0.7792578453784708\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7 - Loss:2.5426: 100%|██████████| 299/299 [03:31<00:00,  1.42it/s]\n",
      "Epoch:7 - Loss:1.6858: 100%|██████████| 233/233 [00:55<00:00,  4.18it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:32:29 2021 \n",
      "\n",
      "    Fold:0, Epoch:7, LR:0.0009054634, Cons. Weight: 0.722473300494024\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.5426   |   1.6858\n",
      "\n",
      "    LWLRAP:              0.8008   |   0.7864\n",
      "\n",
      "    Class Loss:          2.5351   |   1.6756\n",
      "\n",
      "    Consistency Loss:    0.0075   |   0.0102\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.7792578453784708 --> 0.7864181957402296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8 - Loss:2.5371: 100%|██████████| 299/299 [03:29<00:00,  1.42it/s]\n",
      "Epoch:8 - Loss:1.4987: 100%|██████████| 233/233 [00:53<00:00,  4.39it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:36:52 2021 \n",
      "\n",
      "    Fold:0, Epoch:8, LR:0.000975773, Cons. Weight: 0.7296795498593247\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.5371   |   1.4987\n",
      "\n",
      "    LWLRAP:              0.8115   |   0.8204\n",
      "\n",
      "    Class Loss:          2.5289   |   1.4912\n",
      "\n",
      "    Consistency Loss:    0.0082   |   0.0075\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.7864181957402296 --> 0.8203838043558014\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9 - Loss:2.1646: 100%|██████████| 299/299 [03:23<00:00,  1.47it/s]\n",
      "Epoch:9 - Loss:1.3333: 100%|██████████| 233/233 [00:56<00:00,  4.14it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:41:12 2021 \n",
      "\n",
      "    Fold:0, Epoch:9, LR:0.001, Cons. Weight: 0.7369503078148391\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.1646   |   1.3333\n",
      "\n",
      "    LWLRAP:              0.8452   |   0.8271\n",
      "\n",
      "    Class Loss:          2.1574   |   1.3239\n",
      "\n",
      "    Consistency Loss:    0.0073   |   0.0093\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8203838043558014 --> 0.8270851130293855\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:10 - Loss:1.8583: 100%|██████████| 299/299 [03:34<00:00,  1.39it/s]\n",
      "Epoch:10 - Loss:1.7414: 100%|██████████| 233/233 [00:54<00:00,  4.31it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:45:41 2021 \n",
      "\n",
      "    Fold:0, Epoch:10, LR:3.422702e-05, Cons. Weight: 0.7442860710056644\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.8583   |   1.7414\n",
      "\n",
      "    LWLRAP:              0.8545   |   0.7999\n",
      "\n",
      "    Class Loss:          1.8510   |   1.7312\n",
      "\n",
      "    Consistency Loss:    0.0073   |   0.0102\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:11 - Loss:1.9113: 100%|██████████| 299/299 [03:35<00:00,  1.39it/s]\n",
      "Epoch:11 - Loss:1.9100: 100%|██████████| 233/233 [00:52<00:00,  4.47it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:50:09 2021 \n",
      "\n",
      "    Fold:0, Epoch:11, LR:0.0001045366, Cons. Weight: 0.7516873390632673\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.9113   |   1.9100\n",
      "\n",
      "    LWLRAP:              0.8677   |   0.8116\n",
      "\n",
      "    Class Loss:          1.9038   |   1.8964\n",
      "\n",
      "    Consistency Loss:    0.0074   |   0.0136\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:12 - Loss:1.8685: 100%|██████████| 299/299 [03:40<00:00,  1.36it/s]\n",
      "Epoch:12 - Loss:1.1414: 100%|██████████| 233/233 [00:53<00:00,  4.35it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:54:43 2021 \n",
      "\n",
      "    Fold:0, Epoch:12, LR:0.0002140463, Cons. Weight: 0.7591546146151242\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.8685   |   1.1414\n",
      "\n",
      "    LWLRAP:              0.8540   |   0.8636\n",
      "\n",
      "    Class Loss:          1.8612   |   1.1346\n",
      "\n",
      "    Consistency Loss:    0.0073   |   0.0068\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8270851130293855 --> 0.8636105578471035\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:13 - Loss:1.8328: 100%|██████████| 299/299 [03:41<00:00,  1.35it/s]\n",
      "Epoch:13 - Loss:1.9871: 100%|██████████| 233/233 [00:54<00:00,  4.30it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sat Feb  6 23:59:18 2021 \n",
      "\n",
      "    Fold:0, Epoch:13, LR:0.0003520366, Cons. Weight: 0.766688403294309\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.8328   |   1.9871\n",
      "\n",
      "    LWLRAP:              0.8681   |   0.7754\n",
      "\n",
      "    Class Loss:          1.8250   |   1.9770\n",
      "\n",
      "    Consistency Loss:    0.0077   |   0.0101\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:14 - Loss:1.7165: 100%|██████████| 299/299 [03:30<00:00,  1.42it/s]\n",
      "Epoch:14 - Loss:1.5600: 100%|██████████| 233/233 [01:03<00:00,  3.65it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 00:03:53 2021 \n",
      "\n",
      "    Fold:0, Epoch:14, LR:0.000505, Cons. Weight: 0.7742892137490264\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.7165   |   1.5600\n",
      "\n",
      "    LWLRAP:              0.8800   |   0.8438\n",
      "\n",
      "    Class Loss:          1.7089   |   1.5504\n",
      "\n",
      "    Consistency Loss:    0.0076   |   0.0097\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:15 - Loss:1.6900: 100%|██████████| 299/299 [03:35<00:00,  1.38it/s]\n",
      "Epoch:15 - Loss:1.4705: 100%|██████████| 233/233 [00:55<00:00,  4.21it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 00:08:24 2021 \n",
      "\n",
      "    Fold:0, Epoch:15, LR:0.0006579634, Cons. Weight: 0.7819575576520875\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.6900   |   1.4705\n",
      "\n",
      "    LWLRAP:              0.8808   |   0.8149\n",
      "\n",
      "    Class Loss:          1.6824   |   1.4605\n",
      "\n",
      "    Consistency Loss:    0.0076   |   0.0101\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:16 - Loss:1.5322: 100%|██████████| 299/299 [03:32<00:00,  1.41it/s]\n",
      "Epoch:16 - Loss:1.4408: 100%|██████████| 233/233 [00:58<00:00,  4.01it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 00:12:55 2021 \n",
      "\n",
      "    Fold:0, Epoch:16, LR:0.0007959537, Cons. Weight: 0.7896939497103246\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.5322   |   1.4408\n",
      "\n",
      "    LWLRAP:              0.8824   |   0.8432\n",
      "\n",
      "    Class Loss:          1.5245   |   1.4320\n",
      "\n",
      "    Consistency Loss:    0.0078   |   0.0088\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:17 - Loss:1.5913: 100%|██████████| 299/299 [03:36<00:00,  1.38it/s]\n",
      "Epoch:17 - Loss:1.8095: 100%|██████████| 233/233 [00:56<00:00,  4.13it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 00:17:28 2021 \n",
      "\n",
      "    Fold:0, Epoch:17, LR:0.0009054634, Cons. Weight: 0.7974989076739534\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.5913   |   1.8095\n",
      "\n",
      "    LWLRAP:              0.8955   |   0.8083\n",
      "\n",
      "    Class Loss:          1.5833   |   1.8006\n",
      "\n",
      "    Consistency Loss:    0.0081   |   0.0089\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:18 - Loss:1.6840: 100%|██████████| 299/299 [03:28<00:00,  1.44it/s]\n",
      "Epoch:18 - Loss:1.6720: 100%|██████████| 233/233 [00:59<00:00,  3.92it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 00:21:55 2021 \n",
      "\n",
      "    Fold:0, Epoch:18, LR:0.000975773, Cons. Weight: 0.8053729523458644\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.6840   |   1.6720\n",
      "\n",
      "    LWLRAP:              0.8879   |   0.8318\n",
      "\n",
      "    Class Loss:          1.6758   |   1.6656\n",
      "\n",
      "    Consistency Loss:    0.0082   |   0.0065\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:19 - Loss:1.6702: 100%|██████████| 299/299 [03:40<00:00,  1.36it/s]\n",
      "Epoch:19 - Loss:1.2594: 100%|██████████| 233/233 [00:59<00:00,  3.93it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 00:26:35 2021 \n",
      "\n",
      "    Fold:0, Epoch:19, LR:0.001, Cons. Weight: 0.8133166075908668\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.6702   |   1.2594\n",
      "\n",
      "    LWLRAP:              0.8740   |   0.8488\n",
      "\n",
      "    Class Loss:          1.6617   |   1.2517\n",
      "\n",
      "    Consistency Loss:    0.0085   |   0.0077\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:20 - Loss:1.4548: 100%|██████████| 299/299 [03:34<00:00,  1.39it/s]\n",
      "Epoch:20 - Loss:1.3499: 100%|██████████| 233/233 [00:53<00:00,  4.36it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 00:31:03 2021 \n",
      "\n",
      "    Fold:0, Epoch:20, LR:3.422702e-05, Cons. Weight: 0.821330400344857\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.4548   |   1.3499\n",
      "\n",
      "    LWLRAP:              0.9064   |   0.8603\n",
      "\n",
      "    Class Loss:          1.4477   |   1.3393\n",
      "\n",
      "    Consistency Loss:    0.0071   |   0.0106\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:21 - Loss:1.4980: 100%|██████████| 299/299 [03:33<00:00,  1.40it/s]\n",
      "Epoch:21 - Loss:1.1381: 100%|██████████| 233/233 [00:52<00:00,  4.45it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 00:35:29 2021 \n",
      "\n",
      "    Fold:0, Epoch:21, LR:0.0001045366, Cons. Weight: 0.829414860623932\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.4980   |   1.1381\n",
      "\n",
      "    LWLRAP:              0.9050   |   0.8694\n",
      "\n",
      "    Class Loss:          1.4901   |   1.1298\n",
      "\n",
      "    Consistency Loss:    0.0079   |   0.0083\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8636105578471035 --> 0.8693790386828362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:22 - Loss:1.1911: 100%|██████████| 299/299 [03:34<00:00,  1.40it/s]\n",
      "Epoch:22 - Loss:1.8066: 100%|██████████| 233/233 [00:55<00:00,  4.16it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 00:39:59 2021 \n",
      "\n",
      "    Fold:0, Epoch:22, LR:0.0002140463, Cons. Weight: 0.8375705215334286\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1911   |   1.8066\n",
      "\n",
      "    LWLRAP:              0.9202   |   0.8312\n",
      "\n",
      "    Class Loss:          1.1837   |   1.7978\n",
      "\n",
      "    Consistency Loss:    0.0073   |   0.0088\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:23 - Loss:1.4228: 100%|██████████| 299/299 [03:37<00:00,  1.37it/s]\n",
      "Epoch:23 - Loss:1.8585: 100%|██████████| 233/233 [00:57<00:00,  4.09it/s]\n",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 00:44:33 2021 \n",
      "\n",
      "    Fold:0, Epoch:23, LR:0.0003520366, Cons. Weight: 0.8457979192769101\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.4228   |   1.8585\n",
      "\n",
      "    LWLRAP:              0.9047   |   0.8130\n",
      "\n",
      "    Class Loss:          1.4150   |   1.8444\n",
      "\n",
      "    Consistency Loss:    0.0078   |   0.0141\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:24 - Loss:1.4627: 100%|██████████| 299/299 [03:41<00:00,  1.35it/s]\n",
      "Epoch:24 - Loss:1.7956: 100%|██████████| 233/233 [00:53<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Sun Feb  7 00:49:09 2021 \n",
      "\n",
      "    Fold:0, Epoch:24, LR:0.000505, Cons. Weight: 0.8540975931650733\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.4627   |   1.7956\n",
      "\n",
      "    LWLRAP:              0.9075   |   0.8232\n",
      "\n",
      "    Class Loss:          1.4547   |   1.7849\n",
      "\n",
      "    Consistency Loss:    0.0080   |   0.0107\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train(df, fold):\n",
    "    train_df = df[df.fold != fold]\n",
    "    val_df = df[df.fold == fold]\n",
    "    train_loader = get_data_loader(train_df, config.train_batch_size, is_val=False)\n",
    "    val_loader = get_data_loader(val_df, config.valid_batch_size, is_val=True)\n",
    "\n",
    "    student_model = get_model()\n",
    "    teacher_model = get_model(is_mean_teacher=True)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=config.lr)\n",
    "    num_train_steps = int(len(train_loader) * config.epochs)\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001*0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=num_train_steps)\n",
    "    criterion = MeanTeacherLoss()\n",
    "\n",
    "    best_val_metric = -np.inf\n",
    "    val_metrics = []\n",
    "    train_metrics = []\n",
    "    for epoch in range(0, config.epochs):\n",
    "        train_loss_metrics = train_one_epoch(\n",
    "            student_model, teacher_model, train_loader, \n",
    "            criterion, optimizer, scheduler, epoch)\n",
    "        val_loss_metrics = valid_one_epoch(\n",
    "            student_model, teacher_model, val_loader, \n",
    "            criterion, optimizer, scheduler, epoch)\n",
    "\n",
    "        train_metrics.append(train_loss_metrics)\n",
    "        val_metrics.append(val_loss_metrics)\n",
    "        pretty_print_metrics(fold, epoch, optimizer, \n",
    "                             train_loss_metrics, val_loss_metrics)\n",
    "        \n",
    "        if val_loss_metrics['lwlrap'] > best_val_metric:\n",
    "            print(f\"    LWLRAP Improved from {best_val_metric} --> {val_loss_metrics['lwlrap']}\\n\")\n",
    "            torch.save(teacher_model.state_dict(), \n",
    "                       os.path.join(config.save_path, f'fold-{fold}.bin'))\n",
    "            best_val_metric = val_loss_metrics['lwlrap']\n",
    "    \n",
    "\n",
    "\n",
    "df = get_n_fold_df(config.train_tp_csv)\n",
    "for fold in range(5 if config.train_5_folds else 1):\n",
    "    train(df, fold)\n",
    "                  \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 4.591486,
     "end_time": "2021-02-04T14:37:51.530078",
     "exception": false,
     "start_time": "2021-02-04T14:37:46.938592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict on Test Set\n",
    "We'll predict using the teacher model but you could also use the student or a combination of the two. Inference works just like it would for a vanilla baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T14:38:01.120770Z",
     "iopub.status.busy": "2021-02-04T14:38:01.120204Z",
     "iopub.status.idle": "2021-02-04T15:43:30.304793Z",
     "shell.execute_reply": "2021-02-04T15:43:30.305923Z"
    },
    "papermill": {
     "duration": 3933.825159,
     "end_time": "2021-02-04T15:43:30.306153",
     "exception": false,
     "start_time": "2021-02-04T14:37:56.480994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1992 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/user/.local/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/user/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/user/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-5-6beeda66d104>\", line 14, in __getitem__\n    y, sr = sf.read(f\"{self.data_path}/{recording_id}.flac\")\n  File \"/usr/local/lib/python3.6/dist-packages/soundfile.py\", line 257, in read\n    subtype, endian, format, closefd) as f:\n  File \"/usr/local/lib/python3.6/dist-packages/soundfile.py\", line 629, in __init__\n    self._file = self._open(file, mode_int, closefd)\n  File \"/usr/local/lib/python3.6/dist-packages/soundfile.py\", line 1184, in _open\n    \"Error opening {0!r}: \".format(self.name))\n  File \"/usr/local/lib/python3.6/dist-packages/soundfile.py\", line 1357, in _error_check\n    raise RuntimeError(prefix + _ffi.string(err_str).decode('utf-8', 'replace'))\nRuntimeError: Error opening '../input/rfcx-species-audio-detection/test/000316da7.flac': System error.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0f2924cb04f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_5_folds\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-0f2924cb04f1>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(test_df, train_fold)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtest_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_on_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Build Submission File\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6beeda66d104>\u001b[0m in \u001b[0;36mpredict_on_test\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"waveform\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/user/.local/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/user/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/user/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-5-6beeda66d104>\", line 14, in __getitem__\n    y, sr = sf.read(f\"{self.data_path}/{recording_id}.flac\")\n  File \"/usr/local/lib/python3.6/dist-packages/soundfile.py\", line 257, in read\n    subtype, endian, format, closefd) as f:\n  File \"/usr/local/lib/python3.6/dist-packages/soundfile.py\", line 629, in __init__\n    self._file = self._open(file, mode_int, closefd)\n  File \"/usr/local/lib/python3.6/dist-packages/soundfile.py\", line 1184, in _open\n    \"Error opening {0!r}: \".format(self.name))\n  File \"/usr/local/lib/python3.6/dist-packages/soundfile.py\", line 1357, in _error_check\n    raise RuntimeError(prefix + _ffi.string(err_str).decode('utf-8', 'replace'))\nRuntimeError: Error opening '../input/rfcx-species-audio-detection/test/000316da7.flac': System error.\n"
     ]
    }
   ],
   "source": [
    "def test(test_df, train_fold):\n",
    "    test_dataset = TestDataset(\n",
    "        df=test_df,\n",
    "        data_path=\"../input/rfcx-species-audio-detection/test\",\n",
    "        period=config.period,\n",
    "        step=config.step\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=config.num_workers\n",
    "    )\n",
    "    \n",
    "    weights_path = os.path.join(config.save_path, f'fold-{train_fold}.bin')\n",
    "    model = get_model()\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=config.device), strict=False)\n",
    "    \n",
    "    test_pred, ids = predict_on_test(model, test_loader)\n",
    "\n",
    "    # Build Submission File\n",
    "    test_pred_df = pd.DataFrame({\n",
    "        \"recording_id\": test_df.recording_id.values\n",
    "    })\n",
    "    target_cols = test_df.columns[1:].values.tolist()\n",
    "    test_pred_df = test_pred_df.join(pd.DataFrame(np.array(test_pred), \n",
    "                                                  columns=target_cols))\n",
    "    test_pred_df.to_csv(os.path.join(config.save_path, \n",
    "                                     f\"fold-{train_fold}-submission.csv\"), \n",
    "                        index=False)\n",
    "    \n",
    "    \n",
    "test_df = pd.read_csv(config.test_csv)\n",
    "for fold in range(5 if config.train_5_folds else 1):\n",
    "    test(test_df, fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 7.480846,
     "end_time": "2021-02-04T15:43:44.986726",
     "exception": false,
     "start_time": "2021-02-04T15:43:37.505880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5 Fold Ensemble\n",
    "For 5 fold runs, we'll create a single ensemble prediction by simply averaging all of the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T15:44:00.025363Z",
     "iopub.status.busy": "2021-02-04T15:44:00.024518Z",
     "iopub.status.idle": "2021-02-04T15:44:00.216303Z",
     "shell.execute_reply": "2021-02-04T15:44:00.215824Z"
    },
    "papermill": {
     "duration": 7.82881,
     "end_time": "2021-02-04T15:44:00.216429",
     "exception": false,
     "start_time": "2021-02-04T15:43:52.387619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensemble(submission_path):\n",
    "    dfs = [pd.read_csv(os.path.join(\n",
    "        config.save_path, f\"fold-{i}-submission.csv\")) for i in range(5)]\n",
    "    anchor = dfs[0].copy()\n",
    "    cols = anchor.columns[1:]\n",
    "   \n",
    "    for c in cols:\n",
    "        total = 0\n",
    "        for df in dfs:\n",
    "            total += df[c]\n",
    "        anchor[c] = total / len(dfs)\n",
    "    anchor.to_csv(submission_path, index=False)\n",
    "\n",
    "\n",
    "submission_path = os.path.join(config.save_path, f\"submission.csv\")\n",
    "if config.train_5_folds:\n",
    "    ensemble(submission_path)\n",
    "else:\n",
    "    fold0_submission = os.path.join(config.save_path, f\"fold-0-submission.csv\")\n",
    "    os.rename(fold0_submission, submission_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 7.342995,
     "end_time": "2021-02-04T15:44:14.993906",
     "exception": false,
     "start_time": "2021-02-04T15:44:07.650911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion \n",
    "Thanks for reading! I dropped some unrelated tricks from this and didn't spend much time tuning so there's almost definetely room for improvement.\n",
    "\n",
    "I know it's pretty late in the competition for new notebooks, but considering that there are a few other public notebooks that score higher, I'm hoping this won't cause a significant shakeup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19405.783445,
   "end_time": "2021-02-04T15:44:24.896347",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-04T10:20:59.112902",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
