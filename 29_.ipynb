{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch==1.6.0\n",
      "  Downloading torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 748.8 MB 16 kB/s \n",
      "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0) (0.18.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0) (1.17.4)\n",
      "Installing collected packages: torch\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx and convert-onnx-to-caffe2 are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed torch-1.6.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (49.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 49.5 MB 29.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.17.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.4.0.46\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchvision==0.2.2\n",
      "  Downloading torchvision-0.2.2-py2.py3-none-any.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 5.6 MB/s \n",
      "\u001b[?25hCollecting tqdm==4.19.9\n",
      "  Downloading tqdm-4.19.9-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 3.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (1.17.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (1.11.0)\n",
      "Requirement already satisfied: torch in /home/user/.local/lib/python3.6/site-packages (from torchvision==0.2.2) (1.6.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (7.2.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==0.2.2) (0.18.2)\n",
      "Installing collected packages: tqdm, torchvision\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed torchvision-0.2.2 tqdm-4.19.9\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-0.5.2-py3-none-any.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 1.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.17.4)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (36.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 36.7 MB 9.1 MB/s \n",
      "\u001b[?25hCollecting imgaug>=0.4.0\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "\u001b[K     |████████████████████████████████| 948 kB 14.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.1.0)\n",
      "Collecting scikit-image>=0.16.1\n",
      "  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 17.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations) (5.3.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (1.11.0)\n",
      "Collecting imageio\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 9.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (7.2.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (3.0.0)\n",
      "Collecting Shapely\n",
      "  Downloading Shapely-1.7.1-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 15.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /home/user/.local/lib/python3.6/site-packages (from imgaug>=0.4.0->albumentations) (4.4.0.46)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 27.9 MB/s \n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 44.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.7.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug>=0.4.0->albumentations) (49.6.0)\n",
      "Installing collected packages: opencv-python-headless, imageio, PyWavelets, tifffile, scikit-image, Shapely, imgaug, albumentations\n",
      "\u001b[33m  WARNING: The scripts imageio_download_bin and imageio_remove_bin are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts lsm2bin and tifffile are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script skivi is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "scikit-image 0.17.2 requires matplotlib!=3.0.0,>=2.0.0, but you'll have matplotlib 3.0.0 which is incompatible.\u001b[0m\n",
      "Successfully installed PyWavelets-1.1.1 Shapely-1.7.1 albumentations-0.5.2 imageio-2.9.0 imgaug-0.4.0 opencv-python-headless-4.4.0.46 scikit-image-0.17.2 tifffile-2020.9.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.6.0\n",
    "!pip install opencv-python\n",
    "!pip install torchvision==0.2.2\n",
    "!pip install albumentations\n",
    "!pip install tensorflow\n",
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import typing as tp\n",
    "import yaml\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "# import resnest.torch as resnest_torch\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "# from resnet import ResNet, Bottleneck\n",
    "\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_set = {\n",
    "    'dataset': {\n",
    "          'name': 'SpectrogramDataset',\n",
    "          'params': {\n",
    "            'img_size': 224, \n",
    "            'melspectrogram_parameters': {\n",
    "              'n_mels': 128, \n",
    "              'fmin': 50, \n",
    "              'fmax': 15000, \n",
    "            }\n",
    "      }\n",
    "    },\n",
    "    'loader': {\n",
    "      'train': {\n",
    "        'batch_size': 6,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 2,\n",
    "        'pin_memory': True,\n",
    "        'drop_last': True,\n",
    "      },\n",
    "      'valid': {\n",
    "        'batch_size': 2,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 2,\n",
    "        'pin_memory': True,\n",
    "        'drop_last': True,\n",
    "      }\n",
    "    }\n",
    "}\n",
    "SEED=100\n",
    "PERIOD = 5\n",
    "SPECIES_NUM = 24\n",
    "EPOCH = 50\n",
    "OUTPUT_DIR = './output/'\n",
    "HOP_LEN = 512\n",
    "SR = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_ROOT = Path(\"/home/knikaido/work/Rainforest-Connection/data\")\n",
    "RAW_DATA = INPUT_ROOT / \"rfcx-species-audio-detection\"\n",
    "TRAIN_AUDIO_DIR = RAW_DATA / \"train\"\n",
    "# TRAIN_RESAMPLED_AUDIO_DIRS = [\n",
    "#   INPUT_ROOT / \"birdsong-resampled-train-audio-{:0>2}\".format(i)  for i in range(5)\n",
    "# ]\n",
    "TEST_AUDIO_DIR = RAW_DATA / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioTransform(BasicTransform):\n",
    "    \"\"\" Transform for audio task. This is the main class where we override the targets and update params function for our need\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "    \n",
    "class PitchShift(AudioTransform):\n",
    "    \"\"\" Do time shifting of audio \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5 , n_steps=None):\n",
    "        super(PitchShift, self).__init__(always_apply, p)\n",
    "        '''\n",
    "        nsteps here is equal to number of semitones\n",
    "        '''\n",
    "        \n",
    "        self.n_steps = n_steps\n",
    "        \n",
    "    def apply(self,data,**params):\n",
    "        '''\n",
    "        data : ndarray of audio timeseries\n",
    "        '''        \n",
    "        return librosa.effects.pitch_shift(data,sr=SR,n_steps=self.n_steps)\n",
    "    \n",
    "class AddGaussianNoise(AudioTransform):\n",
    "    \"\"\" Do time shifting of audio \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(AddGaussianNoise, self).__init__(always_apply, p)\n",
    "        \n",
    "        \n",
    "    def apply(self,data,**params):\n",
    "        '''\n",
    "        data : ndarray of audio timeseries\n",
    "        ''' \n",
    "        noise = np.random.randn(len(data))\n",
    "        data_wn = data + 0.005*noise\n",
    "        return data_wn\n",
    "    \n",
    "class NoAugment(AudioTransform):\n",
    "    \"\"\" Do time shifting of audio \"\"\"\n",
    "    def __init__(self, always_apply=False):\n",
    "        super(NoAugment, self).__init__(always_apply)\n",
    "        \n",
    "        \n",
    "    def apply(self,data,**params):\n",
    "        '''\n",
    "        data : ndarray of audio timeseries\n",
    "        ''' \n",
    "        return data\n",
    "    \n",
    "def get_augmentation():\n",
    "    train_transform = [\n",
    "#         PitchShift(p=1.0,n_steps=4),\n",
    "        AddGaussianNoise(p=0.2),\n",
    "    ]\n",
    "    return A.OneOf(train_transform)  # <- Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform(BasicTransform):\n",
    "    \"\"\" Transform for audio task. This is the main class where we override the targets and update params function for our need\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "    \n",
    "class SpecAugment(ImageTransform):\n",
    "    \"\"\" Do time shifting of audio \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5 , num_mask=2, \n",
    "                 freq_masking_max_percentage=0.1, time_masking_max_percentage=0.2):\n",
    "        super(SpecAugment, self).__init__(always_apply, p)\n",
    "        '''\n",
    "        nsteps here is equal to number of semitones\n",
    "        '''\n",
    "        \n",
    "        self.num_mask = num_mask\n",
    "        self.freq_masking_max_percentage = freq_masking_max_percentage\n",
    "        self.time_masking_max_percentage = time_masking_max_percentage\n",
    "        \n",
    "    def apply(self,data,**params):\n",
    "        '''\n",
    "        spec : ndarray of mel\n",
    "        '''        \n",
    "        data = data.copy()\n",
    "        for i in range(self.num_mask):\n",
    "            all_frames_num, all_freqs_num = data.shape\n",
    "            freq_percentage = random.uniform(0.0, self.freq_masking_max_percentage)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            data[:, f0:f0 + num_freqs_to_mask] = 0\n",
    "\n",
    "            time_percentage = random.uniform(0.0, self.time_masking_max_percentage)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            data[t0:t0 + num_frames_to_mask, :] = 0\n",
    "\n",
    "        return data\n",
    "    \n",
    "def get_image_augmentation():\n",
    "    train_transform = [\n",
    "#         PitchShift(p=1.0,n_steps=4),\n",
    "        SpecAugment(p=0.2),\n",
    "    ]\n",
    "    return A.OneOf(train_transform)  # <- Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>songtype_id</th>\n",
       "      <th>t_min</th>\n",
       "      <th>f_min</th>\n",
       "      <th>t_max</th>\n",
       "      <th>f_max</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003bec244</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>44.5440</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.1307</td>\n",
       "      <td>5531.25</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006ab765f</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39.9615</td>\n",
       "      <td>7235.160</td>\n",
       "      <td>46.0452</td>\n",
       "      <td>11283.40</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007f87ba2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>39.1360</td>\n",
       "      <td>562.500</td>\n",
       "      <td>42.2720</td>\n",
       "      <td>3281.25</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0099c367b</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>51.4206</td>\n",
       "      <td>1464.260</td>\n",
       "      <td>55.1996</td>\n",
       "      <td>4565.04</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009b760e6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0854</td>\n",
       "      <td>947.461</td>\n",
       "      <td>52.5293</td>\n",
       "      <td>10852.70</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>fe8d9ac40</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>53.4720</td>\n",
       "      <td>93.750</td>\n",
       "      <td>54.0960</td>\n",
       "      <td>843.75</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>fea6b438a</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>43.5787</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.7653</td>\n",
       "      <td>4031.25</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>ff2eb9ce5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2267</td>\n",
       "      <td>5906.250</td>\n",
       "      <td>16.0213</td>\n",
       "      <td>8250.00</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>ffb8d8391</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14.3467</td>\n",
       "      <td>4781.250</td>\n",
       "      <td>16.6987</td>\n",
       "      <td>10406.20</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>ffb9a7b9a</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>40.3200</td>\n",
       "      <td>3187.500</td>\n",
       "      <td>41.0133</td>\n",
       "      <td>5062.50</td>\n",
       "      <td>/home/knikaido/work/Rainforest-Connection/data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1216 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     recording_id  species_id  songtype_id    t_min     f_min    t_max  \\\n",
       "0       003bec244          14            1  44.5440  2531.250  45.1307   \n",
       "1       006ab765f          23            1  39.9615  7235.160  46.0452   \n",
       "2       007f87ba2          12            1  39.1360   562.500  42.2720   \n",
       "3       0099c367b          17            4  51.4206  1464.260  55.1996   \n",
       "4       009b760e6          10            1  50.0854   947.461  52.5293   \n",
       "...           ...         ...          ...      ...       ...      ...   \n",
       "1211    fe8d9ac40          13            1  53.4720    93.750  54.0960   \n",
       "1212    fea6b438a           4            1  43.5787  2531.250  45.7653   \n",
       "1213    ff2eb9ce5           0            1  15.2267  5906.250  16.0213   \n",
       "1214    ffb8d8391           5            1  14.3467  4781.250  16.6987   \n",
       "1215    ffb9a7b9a          18            1  40.3200  3187.500  41.0133   \n",
       "\n",
       "         f_max                                               name  \n",
       "0      5531.25  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1     11283.40  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "2      3281.25  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "3      4565.04  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "4     10852.70  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "...        ...                                                ...  \n",
       "1211    843.75  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1212   4031.25  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1213   8250.00  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1214  10406.20  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "1215   5062.50  /home/knikaido/work/Rainforest-Connection/data...  \n",
       "\n",
       "[1216 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gby = pd.read_pickle(RAW_DATA / \"train_gby_wav_raw.pkl\")\n",
    "train_gby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(\n",
    "    X: np.ndarray, mean=None, std=None,\n",
    "    norm_max=None, norm_min=None, eps=1e-6\n",
    "):\n",
    "    # Stack X as [X,X,X]\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    X = X - mean\n",
    "    std = std or X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Normalize to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_augment(spec: np.ndarray, num_mask=2, \n",
    "                 freq_masking_max_percentage=0.1, time_masking_max_percentage=0.2):\n",
    "\n",
    "    spec = spec.copy()\n",
    "    for i in range(num_mask):\n",
    "        all_frames_num, all_freqs_num = spec.shape\n",
    "        freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "        \n",
    "        num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "        f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "        f0 = int(f0)\n",
    "        spec[:, f0:f0 + num_freqs_to_mask] = 0\n",
    "\n",
    "        time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "        \n",
    "        num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "        t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "        t0 = int(t0)\n",
    "        spec[t0:t0 + num_frames_to_mask, :] = 0\n",
    "    \n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramTrainDataset(data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gby_df: pd.DataFrame,\n",
    "        setting: tp.Dict\n",
    "    ):\n",
    "        self.img_size = setting['img_size']\n",
    "        self.melspectrogram_parameters = setting['melspectrogram_parameters']\n",
    "        self.transform = get_augmentation()\n",
    "        self.imagetransform = get_image_augmentation()\n",
    "        \n",
    "        self.gby_df = gby_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gby_df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \n",
    "        wav_path = self.gby_df['name'][idx]\n",
    "        train_element = self.gby_df.iloc[idx]\n",
    "        \n",
    "        y, sr = sf.read(wav_path)\n",
    "    \n",
    "        len_y = len(y)\n",
    "        effective_length = sr * PERIOD\n",
    "\n",
    "        tmin = int(SR * train_element['t_min'])\n",
    "        tmax = int(SR * train_element['t_max'])\n",
    "        \n",
    "        #時間かかる\n",
    "        while(1):\n",
    "            start = np.random.randint(len_y - effective_length)\n",
    "            end = start + effective_length\n",
    "            tgt_len = int((tmax - tmin) / 2)\n",
    "            if( (start < tmin and tmin + tgt_len < end) or (start < tmax - tgt_len and tmax < end) ):\n",
    "                break\n",
    "        \n",
    "        y = y[start:end].astype(np.float32)\n",
    "        y = self.transform(data=y)['data']\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "        melspec = self.imagetransform(data=melspec)['data']\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "        \n",
    "        label = np.zeros(SPECIES_NUM, dtype=\"f\")\n",
    "        label[train_element['species_id']] = 1\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "class SpectrogramValidDataset(data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gby_df: pd.DataFrame,\n",
    "        setting: tp.Dict\n",
    "    ):\n",
    "        self.img_size = setting['img_size']\n",
    "        self.melspectrogram_parameters = setting['melspectrogram_parameters']\n",
    "        \n",
    "        self.gby_df = gby_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gby_df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \n",
    "        wav_path = self.gby_df['name'][idx]\n",
    "        train_element = self.gby_df.iloc[idx]\n",
    "        \n",
    "        y, sr = sf.read(wav_path)\n",
    "        \n",
    "        len_y = len(y)\n",
    "        effective_length = sr * PERIOD\n",
    "\n",
    "        tmin = int(SR * train_element['t_min'])\n",
    "        tmax = int(SR * train_element['t_max'])\n",
    "        \n",
    "        #時間かかる\n",
    "        while(1):\n",
    "            start = np.random.randint(len_y - effective_length)\n",
    "            end = start + effective_length\n",
    "            tgt_len = int((tmax - tmin) / 2)\n",
    "            if( (start < tmin and tmin + tgt_len < end) or (start < tmax - tgt_len and tmax < end) ):\n",
    "                break\n",
    "        \n",
    "        y = y[start:end].astype(np.float32)\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "        \n",
    "        label = np.zeros(SPECIES_NUM, dtype=\"f\")\n",
    "        label[train_element['species_id']] = 1\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion():\n",
    "    pos_weights = torch.ones(SPECIES_NUM)\n",
    "    pos_weights = pos_weights * SPECIES_NUM\n",
    "    loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='valid_epoch_loss',\n",
    "   min_delta=0.00,\n",
    "   patience=5,\n",
    "   verbose=True,\n",
    "   mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4167)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "def lwlrap(truth, scores):\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = _one_sample_positive_class_precisions(scores[sample_num, :], truth[sample_num, :])\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = precision_at_hits\n",
    "\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    return per_class_lwlrap, weight_per_class\n",
    "\n",
    "def lwlap_wrapper(y_true, y_score):\n",
    "    y_true = y_true.to('cpu').detach().numpy().copy()\n",
    "    y_score = y_score.to('cpu').detach().numpy().copy()\n",
    "    score_class, weight = lwlrap(y_true, y_score)\n",
    "    score_class = torch.from_numpy(score_class.astype(np.float32)).clone()\n",
    "    weight = torch.from_numpy(weight.astype(np.float32)).clone()\n",
    "    return score_class, weight\n",
    "\n",
    "y_true = np.array([[1, 0, 0], [0, 0, 1]])\n",
    "y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])\n",
    "y_true = torch.from_numpy(y_true.astype(np.float32)).clone()\n",
    "y_score = torch.from_numpy(y_score.astype(np.float32)).clone()\n",
    "\n",
    "score_class, weight = lwlap_wrapper(y_true, y_score)\n",
    "score = (score_class * weight).sum()\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModule(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n",
    "        self.encoder.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1024, SPECIES_NUM)\n",
    "        )\n",
    "        \n",
    "        self.criterion = get_criterion()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_out = self.encoder(x)\n",
    "        return x_out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=0.0001, momentum=0.9)\n",
    "#         optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        y_pred = self.encoder(x)    \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        y_pred = self.encoder(x)\n",
    "        loss = self.criterion(y_pred, y)\n",
    "        lwlap_step, weight_step = lwlap_wrapper(y, y_pred)\n",
    "        lwlap_step = (lwlap_step * weight_step).sum()\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('lwlap_score', lwlap_step, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss, lwlap_step\n",
    "\n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        validation_step_outputs = np.array(validation_step_outputs)\n",
    "        validation_step_losses = validation_step_outputs[:, 0]\n",
    "        mean_loss = torch.stack([x for x in validation_step_losses]).mean()\n",
    "        \n",
    "        validation_step_scores = validation_step_outputs[:, 1]\n",
    "        mean_score = torch.stack([x for x in validation_step_scores]).mean()\n",
    "\n",
    "        print('valid_epoch_loss = ', mean_loss)\n",
    "        print('valid_epoch_lwlap = ', mean_score)\n",
    "        self.log('valid_epoch_loss', mean_loss, prog_bar=True, logger=True)\n",
    "        self.log('valid_epoch_lwlap', mean_score, prog_bar=True, logger=True)\n",
    "#         tqdm.write('Dice: \\t%.3f' % mean_loss)\n",
    "        return mean_loss, mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_gby, train_gby['species_id'])):\n",
    "    # Picking only first fold to train/val on\n",
    "    # This means loss of 20% training data\n",
    "    # To avoid this, you can train 5 different models on 5 folds and average predictions\n",
    "    train_data = train_gby.iloc[train_index]\n",
    "    valid_data = train_gby.iloc[val_index]\n",
    "    train_data.reset_index(drop=True, inplace=True)\n",
    "    valid_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    train_dataset = SpectrogramTrainDataset(train_data, config[\"dataset\"][\"params\"])\n",
    "    valid_dataset = SpectrogramValidDataset(valid_data, config[\"dataset\"][\"params\"])\n",
    "    \n",
    "    train_loader = data.DataLoader(train_dataset, **config[\"loader\"][\"train\"])\n",
    "    valid_loader = data.DataLoader(valid_dataset, **config[\"loader\"][\"valid\"])\n",
    "    \n",
    "#     model = LitModule()\n",
    "    \n",
    "#     trainer = pl.Trainer(\n",
    "#         max_epochs=EPOCH,\n",
    "#         default_root_dir=OUTPUT_DIR,\n",
    "#         gpus=1,\n",
    "#         callbacks=[early_stop_callback]\n",
    "#     )\n",
    "#     trainer.fit(model, train_loader, valid_loader)\n",
    "    \n",
    "#     break\n",
    "    \n",
    "#     torch.save(model.state_dict(), OUTPUT_DIR + 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data_, target) in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f54b2727e80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data__ = data_.to('cpu').detach().numpy().copy()\n",
    "plt.figure()\n",
    "plt.imshow(np.moveaxis(data__[5], 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/user/.cache/torch/hub/zhanghang1989_ResNeSt_master\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | encoder   | ResNet            | 28.6 M\n",
      "1 | criterion | BCEWithLogitsLoss | 0     \n",
      "------------------------------------------------\n",
      "28.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.6 M    Total params\n",
      "/home/user/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06214b0c9dc147b7991b1f93078bcdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(1.3447, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.1306)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The validation_epoch_end should not return anything as of 9.1. To log, use self.log(...) or self.write(...) directly in the LightningModule\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/user/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f6cab368b247c787c416f06ab2bab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e6b0d77d3a4b87ad1f82e058ba0462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(1.3451, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.2159)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311e408cbe28405c9376440eb5e5e2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(1.3105, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.2427)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57134406bda64645b0b0a4c29a4e8283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(1.2160, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.2668)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e882a045474092bcf8fe68bb578433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(1.1564, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.2798)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012ee884b5ce476f9c3eb9ca7800162c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(1.1084, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.3190)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b29a4acc4734dfdac8cc3751c8b015b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(1.0726, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.3360)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346822e93af94c40a0f41cbf03cd1843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(1.0258, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.4157)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7f16e239ca49d098cbfb2c7a0ac7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.9806, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.4408)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118a1229433b419ab6936a529b1e6461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.9092, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.5163)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446123b2915f44ddaef5c299893c31ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.8641, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.5349)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983c6991c5f44952a94e224d795088f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.8101, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.5673)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a3354b6e8d4111a73a10f9fce50526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.7543, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.6101)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05b0c088d41479d97617e2807bb63e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.6689, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.6225)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ac19684cd14fa98c30536efc0ebad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.6266, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.6577)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b95f52808d41c9a735093c275b1689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.6382, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.6487)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9197a5e93d8a4074a38714d590ef152e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.6523, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.6252)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f874d8308842fea501a16ed375b91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.6763, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.6445)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad8793e797a4a9db3cf8b8d410692d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.5347, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7334)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b330c69314d54aff8300b3ed01af7386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.5414, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7064)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b268404f89f4350a10cebc2695fbcc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.5437, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7465)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a6538c71de49cb922a3b3820c12348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.5004, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7640)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2026613a6a2942dbb8854b62391186b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.4892, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7429)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8babd8671304bcd9c319da14d5973d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.5038, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7679)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f5a5a231b041f09ea2f56c3a0263bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.4910, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7878)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2db5ac00de44989a53421590f8951e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.5485, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7880)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ece91b31ec43519289bdc89d737004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.5180, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7886)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a780d7f491fd45289398efc0df06bdb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.4702, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.7983)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f50a28224ca42658f64fcb6bd1e36d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.4204, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8165)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0486644d9bb437dbcef3ee1b513c3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.4655, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8081)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82d8df442134c9f848924990968ce60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.4716, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8211)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6359d41efb45c99e7cb089c895bc85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.4453, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8212)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8456c1d25c4857809810655170badf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_epoch_loss =  tensor(0.4767, device='cuda:0')\n",
      "valid_epoch_lwlap =  tensor(0.8190)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b024d07d57438b89e76dc5fe4ca4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_gby, train_gby['species_id'])):\n",
    "    # Picking only first fold to train/val on\n",
    "    # This means loss of 20% training data\n",
    "    # To avoid this, you can train 5 different models on 5 folds and average predictions\n",
    "    train_data = train_gby.iloc[train_index]\n",
    "    valid_data = train_gby.iloc[val_index]\n",
    "    train_data.reset_index(drop=True, inplace=True)\n",
    "    valid_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    train_dataset = SpectrogramTrainDataset(train_data, config[\"dataset\"][\"params\"])\n",
    "    valid_dataset = SpectrogramValidDataset(valid_data, config[\"dataset\"][\"params\"])\n",
    "    \n",
    "    train_loader = data.DataLoader(train_dataset, **config[\"loader\"][\"train\"])\n",
    "    valid_loader = data.DataLoader(valid_dataset, **config[\"loader\"][\"valid\"])\n",
    "    \n",
    "    model = LitModule()\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=EPOCH,\n",
    "        default_root_dir=OUTPUT_DIR,\n",
    "        gpus=1,\n",
    "        callbacks=[early_stop_callback]\n",
    "    )\n",
    "    trainer.fit(model, train_loader, valid_loader)\n",
    "    \n",
    "    break\n",
    "    \n",
    "    torch.save(model.state_dict(), OUTPUT_DIR + 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), OUTPUT_DIR + 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
