# Rainforest-Connection


---
- 12/15

データを落として，中身みた．種類がよくわからん…？なんでtrain_fo, train_tpどっちにも同じidがいるんだろ． \
聞き耳した感じ，ラベル付が合っているような気がしないんだけど… \
[ベースライン](https://www.kaggle.com/fffrrt/all-in-one-rfcx-baseline-for-beginners)の1つを見たら，tmin,tmaxをwavの時点で取り出して，fmin,fmaxはmelへの変換の時使っていた．

---
- 12/18

上のベースラインは，csvに一致するwavをとってきて(ここでtmin, tmax, fmin, fmaxのメルにもしちゃう)，学習はそれを使ってるっぽい． \
音の長さとか，サンプリングレートはすべて一緒だった．やさしい． \
train_tpにないwavどうつかえばいいんだろ…？ \
第一陣の方針としては， 
1. pytorch lightningをつかう
2. モデルは適当(ResNet34？)
3. Wavは，csv(train_tpにあるやつ)
4. メルをつかうか，wavを毎回へんかんするかはどうしようかね．
5. 学習に使う区間は，tmin, tmaxがはいるようにランダムにとる．(2つ以上ある場合は，どちらでもよい)
6. fmax, fminは，02.ipynbによると，50~15000くらいをとればはいってきそう．

--- 
- 12/19

上記第一陣の方針を進めている．03.ipynbで，train_tpを整理した． \
01.ipynbで，pytorch_lightningを進めているが，なんだか学習が遅い気がする．後，スケジューラーはまだ対応していない．

--- 
- 12/20

01.ipynbで遅かった理由は，GPU使えていなかったからだった． \
04でとりあえず第一陣提出．あいかわらずスケジューラはまだ． \
05.ipynbでメルだした．ただ，今回学習速いから音でやっても良いかも．06は03のmel版． \
07で，ランダムのとり方をもとに戻したらちょっとのびた．あと，sigmoidじゃなくてsoftmaxのほうがよさそう．

---
- 12/21

08で，learning_rate小さくしたら伸びた．スケジューラはなんかうまく行かなかった．ピリオドは5がちょうどよさそう．(ほかは09でためした．) \
種類が，レコーディングidでこていしちゃったほうがいいのかもしれない…train_tpに合わせて変えたらなぜかおちた． \
メルのパラメータは要検討． 

---
- 12/22

なにすればのびんのかよくわかんなくなってきた． \
とりあえず，10_foldでミックスアップを試したが，LBは伸びなかった．そのあと，今回のメトリックをエポック終了時に出せるようにした． \
12は，音でやった．メルの代わりに．どっちがいいんだ．11は残骸．

---
- 12/23

14でaugmentためした．ガウスノイズきくんかこれ…きかなそう．いれたりいれなかったりを，13でためした． \
なんか，08とおなじしくみを13でやったはずなのに，さがってしまった．12と13(augなし)のさは多分殆ど無い．ピッチシフト試したいね．
15で，少しランダムの範囲を狭めたら，伸びた．

---
- 12/24

08_anotherで，08をどうやったらスコア悪くなるのか試したら，おためしのdataloader通すかどうかでかわった．意味不明． \
16.ipynbは，その結果を用いて音で読み込む方のスコア改善するか試したけど，微妙． \
17.ipynbは，メルでスケジューラーとかもう一回試したけどやっぱ微妙．もうわけがわからん…
